<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[python数据可视化seaborn（四）—— 分类数据可视化]]></title>
    <url>%2Fblogs%2F36032875%2F</url>
    <content type="text"><![CDATA[之前的文章关注的是两个变量都是数值变量的情况,当有一个变量是分类变量的时候，我们就需要其他类型的图形来展示分析数据。在seaborn中有多种类型的图形且非常易于上手。 1234567891011import numpy as npimport pandas as pdimport matplotlib.pyplot as pltimport seaborn as sns%matplotlib inlinesns.set(style="whitegrid",font_scale=1.4,context="paper")# 设置风格、尺度import warningswarnings.filterwarnings('ignore') # 不发出警告 seaborn中，分类图主要分为三个部分： 分类散点图： stripplot(默认，kind = “strip”) swarmplot(kind = “swarm”) 分类分布图： boxplot(kind=”box”) violinplot(kind=”violin”) boxenplot(kind=”boxen”) 分类估计图： pointplot(kind=”point”) barplot(kind=”bar”) countplot(kind=”count”) 以上三种系列分别代表了不同粒度级别的数据。当然，在实际使用的过程中，其实没有必要记住这么多，因为seaborn中的分类系列有统一的图形界面catplot(),只需要这一个函数，就能访问所有分类图像类型。 分类散点图seaborn.stripplot(x=None, y=None, hue=None, data=None, order=None, hue_order=None, jitter=True, dodge=False, orient=None, color=None, palette=None, size=5, edgecolor=’gray’, linewidth=0, ax=None, **kwargs) jitter : 是否抖动，True，false or float dodge : 当有hue参数时，是否沿轴分离不同颜色 orient : 图形方向，垂直（“v”）或者水平(“h”) 12345678910111213141516# 1、catplot() 默认情况下，kind='strip'# 按照不同类别对样本数据进行分布散点图绘制tips = sns.load_dataset("tips")print(tips.head())# 加载数据sns.catplot(x="day", # x → 设置分组统计字段 y="total_bill", # y → 数据分布统计字段 # 这里xy数据对调，将会使得散点图横向分布 data=tips, # data → 对应数据 jitter = True, height=6, #当点数据重合较多时，jitter可以控制点抖动，也可以设置间距如：jitter = 0.1 s = 6, edgecolor = 'w',linewidth=1,marker = 'o' , # 设置点的大小、描边颜色或宽度、点样式 ) total_bill tip sex smoker day time size 0 16.99 1.01 Female No Sun Dinner 2 1 10.34 1.66 Male No Sun Dinner 3 2 21.01 3.50 Male No Sun Dinner 3 3 23.68 3.31 Male No Sun Dinner 2 4 24.59 3.61 Female No Sun Dinner 4 123456# 1、stripplot()# 通过kind='swarm' 来调整点防止重合sns.catplot(x="day", y="total_bill",kind='swarm', hue='sex',data=tips,height=5,s=5.5)# 通过让点沿轴分布来防止重合，这只使用与较小数据集 12345678# 1、stripplot()# 设置调色盘sns.catplot(x="sex", y="total_bill", hue="day", data=tips, jitter=True, palette="Set2", # 设置调色盘 dodge=True, # 是否拆分 ) 1234567# 排序print(tips['day'].value_counts())# 查看day字段的唯一值sns.catplot(x="day", y="total_bill", data=tips, order = ['Sun','Sat'])# order → 筛选类别,控制排序 Sat 87 Sun 76 Thur 62 Fri 19 Name: day, dtype: int64 分类分布图箱线图 boxplot()seaborn.boxplot(x=None, y=None, hue=None, data=None, order=None, hue_order=None, orient=None, color=None, palette=None, saturation=0.75, width=0.8, dodge=True, fliersize=5, linewidth=None, whis=1.5, notch=False, ax=None, **kwargs) saturation : float,颜色饱和度 fliersize : 异常值标记的大小 whis : float,超出IQR多少比例被视为异常值，默认1.5 notch : 是否用中位数设置凹槽 12345678910# 箱线图 catplot(kind='box')sns.catplot(x='day', y='total_bill', data=tips, kind='box',linewidth=2, # 线宽 width=0.6, # 箱之间的间隔比例 fliersize=5, # 异常点大小 palette='hls', # 调色板 whis=1.5, # 设置IQR notch=True, # 设置是否用中位数做凹槽 order=['Thur', 'Fri', 'Sat', 'Sun'], #筛选类别 ) 123456789101112# 通过hue参数再分类# 多种类型图混合# 绘制箱型图sns.catplot(x="day", y="total_bill", data=tips, kind='box',hue = 'smoker',height=6)# 绘制散点图sns.swarmplot(x="day", y="total_bill", data=tips, color ='k',s= 3,alpha = 0.8)# 添加分类散点图，这里添加散点图要用各自的函数swarmplot()# 不能再用高级端口catplot() 否则就是两个图了 对于数据量较大的数据集，散点图会显的很拥挤，这时我们可以使用boxenplot(),这种图表类似箱线图，既能够展示数据的分布也可以如箱线图展示数据的统计信息 12345diamonds = sns.load_dataset("diamonds")print(diamonds.head(3))sns.catplot(x='color',y='price',kind='boxen', data=diamonds.sort_values("color"), height=6) carat cut color clarity depth table price x y z 0 0.23 Ideal E SI2 61.5 55.0 326 3.95 3.98 2.43 1 0.21 Premium E SI1 59.8 61.0 326 3.89 3.84 2.31 2 0.23 Good E VS1 56.9 65.0 327 4.05 4.07 2.31 提琴图小提琴图将核密度估计和箱线图结合起来 seaborn.violinplot(x=None, y=None, hue=None, data=None, order=None, hue_order=None, bw=’scott’, cut=2, scale=’area’, scale_hue=True, gridsize=100, width=0.8, inner=’box’, split=False, dodge=True, orient=None, linewidth=None, color=None, palette=None, saturation=0.75, ax=None, **kwargs) bw : (“scott”,”silverman”,float),核大小的比例因子，实际效果是越大越平滑。 cut : float,用于将密度扩展到极端数据点之外的距离，设置为0以将小提琴范围限制在观测数据的范围内。 scale : 小提琴图的宽度：area-面积相同，count-按照样本数量决定宽度，width-宽度一样 scale_hue : bool,当有hue时，决定实在分组内还是图上所有小提琴计算缩放比例 gridsize : 和必读估计离散网格中的点数，越高越平滑 inner : （“box”, “quartile”, “point”, “stick”, None），内部显示样式 split : 当有颜色嵌套是，是否分别绘制每侧的小提琴。 123456789101112131415# 2、violinplot()# 小提琴图sns.catplot(x="day", y="total_bill", data=tips, kind='violin',linewidth = 2, # 线宽 width = 0.8, # 箱之间的间隔比例 height=6,palette = 'hls', # 设置调色板 order = ['Thur','Fri','Sat','Sun'], # 筛选类别 scale = 'area', # 测度小提琴图的宽度： # area-面积相同，count-按照样本数量决定宽度，width-宽度一样 gridsize = 30, # 设置小提琴图边线的平滑度，越高越平滑 inner = 'box', bw = .5 # 控制拟合程度，一般可以不设置 ) 1234567# 2、violinplot()# 通过hue参数再分类sns.catplot(x="day", y="total_bill", data=tips, kind='violin',hue = 'smoker', palette="muted", split=True, # 设置是否拆分小提琴图 inner="quartile",height=6) 123456789101112# 2、violinplot()# 结合散点图sns.catplot(x="day", y="total_bill", data=tips, kind='violin',palette = 'hls', inner = None,height=6, cut=0 # 设置为0，将图限制在观测数据范围内。 )# 插入散点图sns.swarmplot(x="day", y="total_bill", data=tips, color="k", alpha=.5) 统计图seaborn.barplot(x=None, y=None, hue=None, data=None, order=None, hue_order=None, estimator=&lt;\function mean&gt;, ci=95, n_boot=1000, units=None, orient=None, color=None, palette=None, saturation=0.75, errcolor=’.26’, errwidth=None, capsize=None, dodge=True, ax=None, **kwargs) estimator : 分类箱内使用的统计函数 ci : （float,”sd”,None） units : 变量名称，对变量的每个采样单独绘制，可用于绘制重复数据 errwidth : 误差线宽度 capsize : 误差条帽的宽度 123456789101112131415161718# 1、barplot()# 置信区间：样本均值 + 抽样误差titanic = sns.load_dataset("titanic")# print(titanic.head())# 加载数据sns.catplot(x="sex", y="survived", data=titanic, kind='bar',palette = 'hls', hue="class", order = ['male','female'], # 筛选类别 capsize = 0.05, # 误差线横向延伸宽度 saturation=.8, # 颜色饱和度 errcolor = 'gray',errwidth = 2, # 误差线颜色，宽度 height=6,ci = 'sd' # 置信区间误差 → 0-100内值、'sd'、None )print(titanic.groupby(['sex','class']).mean()['survived'])print(titanic.groupby(['sex','class']).std()['survived'])# 计算数据 sex class female First 0.968085 Second 0.921053 Third 0.500000 male First 0.368852 Second 0.157407 Third 0.135447 Name: survived, dtype: float64 sex class female First 0.176716 Second 0.271448 Third 0.501745 male First 0.484484 Second 0.365882 Third 0.342694 Name: survived, dtype: float64 1234567# 1、barplot()# 柱状图 - 置信区间估计# 可以这样子改变风格sns.catplot(x="day", y="total_bill", data=tips, linewidth=2.5,facecolor=(1,1,1,0), kind='bar',edgecolor = 'k',) 123456789101112131415161718192021# 1、barplot()crashes = sns.load_dataset("car_crashes").sort_values("total", ascending=False)print(crashes.head())# 加载数据f, ax = plt.subplots(figsize=(10, 15))# 创建图表# sns.set_color_codes("pastel")sns.barplot(x="total", y="abbrev", data=crashes, label="Total", color="b",edgecolor = 'w')# 设置第一个柱状图# sns.set_color_codes("muted")sns.barplot(x="alcohol", y="abbrev", data=crashes, label="Alcohol-involved", color="y",edgecolor = 'w')# 设置第二个柱状图ax.legend(ncol=2, loc="lower right")sns.despine(left=True, bottom=True) total speeding alcohol not_distracted no_previous ins_premium \ 40 23.9 9.082 9.799 22.944 19.359 858.97 34 23.9 5.497 10.038 23.661 20.554 688.75 48 23.8 8.092 6.664 23.086 20.706 992.61 3 22.4 4.032 5.824 21.056 21.280 827.34 17 21.4 4.066 4.922 16.692 16.264 872.51 ins_losses abbrev 40 116.29 SC 34 109.72 ND 48 152.56 WV 3 142.39 AR 17 137.13 KY 12345678910# 2、countplot()# 计数柱状图sns.catplot(x="class", hue="who", data=titanic, kind='count',palette = 'magma')sns.catplot(y="class", hue="who", data=titanic, kind='count',palette = 'magma') # x/y → 以x或者y轴绘图（横向，竖向）# 用法和barplot相似 12345678910# 3、pointplot()sns.catplot(x="time", y="total_bill", hue = 'smoker',data=tips, kind='point',palette = 'hls',height=7, dodge = True, # 设置点是否分开 join = True, # 是否连线 markers=["o", "x"], linestyles=["-", "--"], # 设置点样式、线型 )# 计算数据# # 用法和barplot相似]]></content>
      <categories>
        <category>python</category>
        <category>可视化</category>
      </categories>
      <tags>
        <tag>可视化</tag>
        <tag>python</tag>
        <tag>seaborn</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python数据可视化seaborn（三）——探索变量之间的关系]]></title>
    <url>%2Fblogs%2F8d288665%2F</url>
    <content type="text"><![CDATA[我们常常想知道变量之间是否存在关联，以及这些关联是否收到其他变量影响。可视化能够帮助我们非常直观的展示这些。 123456789101112import numpy as npimport pandas as pdimport matplotlib.pyplot as pltimport seaborn as sns%matplotlib inlineimport warningswarnings.filterwarnings('ignore') # 不发出警告sns.set_context('notebook',font_scale=1.2)tips = sns.load_dataset("tips")tips.head() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } total_bill tip sex smoker day time size 0 16.99 1.01 Female No Sun Dinner 2 1 10.34 1.66 Male No Sun Dinner 3 2 21.01 3.50 Male No Sun Dinner 3 3 23.68 3.31 Male No Sun Dinner 2 4 24.59 3.61 Female No Sun Dinner 4 relplot这是一个seaborn新的图形级函数，通过kind参数，能对scatterplot()和lineplot()两个轴级函数进行访问。 seaborn.relplot(x=None, y=None, hue=None, size=None, style=None, data=None, row=None, col=None, col_wrap=None, row_order=None, col_order=None, palette=None, hue_order=None, hue_norm=None, sizes=None, size_order=None, size_norm=None, markers=None, dashes=None, style_order=None, legend=’brief’, kind=’scatter’, height=5, aspect=1, facet_kws=None, **kwargs) [hue,size,style]: 可以生成不同的颜色，大小，样式来独立的显示第三个变量 [row,col]: 按照某个变量分列或者分行 col_wrap: int, 分成几列（不能与参数row共同出现） sizes: 对size参数的每个分类设定大小 大小值列表 变量到大小的字典映射 包含最大最小的元组,会在此范围对值归一化 [col,row,size,hue,style]_order: 指定变量出现的顺序。 hue_norm: 当hue的变量值数字时，用于将colormap标准化，如果是分类变量则无关。 size_norm: 数据单元的标准化，当size变量为数字时缩放图像 legend: 如何绘制图例 False：不绘制图例 ‘brief’(默认)：数值型的hue和size参数会用均匀间隔的样本表示 ‘full’：对比‘brief’,每个组都会在图例中输出一个条目 facet_kws: 要传递给FacetGrid其他参数的字典 散点图1234567sns.relplot(x="total_bill", y="tip", data=tips, kind='scatter', # ['scatter','line'] hue='day', # 设置按颜色分类的第三变量# style='day', # 设置形状分类 palette='husl',s=60, # 设置调色盘类型和散点大小 aspect=1.5,height=6 # 设置图像大小和横纵比 ) 可以看到，小费与消费总体呈线性正相关，那精确到不同日期，有什么不同么？上图颜色虽有区分但是不够明显，seaborn可以将分类变量分别绘制到不同的子图中，如下图所示： 123456sns.relplot(x="total_bill", y="tip", data=tips, hue="time", # 用颜色对time变量分类 col="day", # 按照day变量分列 col_wrap=2, # 每行2个分类 s=100, # 散点大小（来自plt.scatter的参数） height=3,aspect=1.5)# 图像大小及每个轴的横纵比 当然，也可以用大小来展示变量的大小强弱等 12345sns.relplot(x="total_bill", y="tip", data=tips, hue="time", size="size", palette=["b", "r"], sizes=(30, 120),# size大小按照最小20最大120分布 col="time")# 按照time分列 当然也可以将点设置成不同的形状来区分类别，但是不建议单独将一个变量与形状表示，因为形状的区分不是很明显，建议和颜色一同使用。 12sns.relplot(x='total_bill',y='tip',data=tips, hue='smoker',style='smoker',s=50) 颜色既可以展示离散变量，也可以展示连续变量，还可以对调色盘自定义 12sns.relplot(x='total_bill',y='tip',data=tips, hue='size',palette='ch:r=-.5,l=.75') 线图用relpot绘制线图其实是对lineplot()函数的访问，所以lineplot的所有参数都可以用在这里面。同样的，scatterplot()函数的参数设置与此几乎相同。seaborn.lineplot(x=None, y=None, hue=None, size=None, style=None, data=None, palette=None, hue_order=None, hue_norm=None, sizes=None, size_order=None, size_norm=None, dashes=True, markers=None, style_order=None, units=None, estimator=’mean’, ci=95, n_boot=1000, sort=True, err_style=’band’, err_kws=None, legend=’brief’, ax=None, **kwargs) units: 对变量的每个采样单独绘制，但不会绘制图例。可用于绘制重复数据。 estimator：pandas方法的名称或None,对同一x变量的多个观察值进行聚合的方法。 ci: [int,’sd’,None],置信区间的大小，当为‘sd’时绘制数据的标准差。 n_boot: int, 计算置信区间的bootstrap数 sort: bool, 数据将按照x和y变量排序，否则将按照他们在数据集中的顺序排列点 err_style: “band”和”bars”,置信区间风格 1234567fmri = sns.load_dataset("fmri")print(fmri.head())g = sns.relplot(x="timepoint", y="signal", data=fmri, hue="event", style="event", col="region", markers=True,dashes=False,# 添加标记，禁止虚线 kind="line") subject timepoint event region signal 0 s13 18 stim parietal -0.017552 1 s5 14 stim parietal -0.080883 2 s12 18 stim parietal -0.081033 3 s11 18 stim parietal -0.046134 4 s10 18 stim parietal -0.037970 lineplot()在默认情况下会将x按照数值进行排序，也可以禁止。 对于某些复杂的数据集，例如上面的fmri数据集。同一个x会有多个测量值。seaborn的默认行为是通过绘制平均值和平均值周围的95%置信区间来聚合每个x的多个测量值。对于大型数据绘制置信区间可能会用较长时间，所以可以通过ci=None来禁止。当然也可以将置信区间替换成标准差ci=&quot;sd&quot; 123sns.relplot(x="timepoint", y="signal", data=fmri,sort=False, # 禁止对x排序 kind="line",ci=False) # 禁止有置信区间 要完全关闭聚合，可以这么设置estimator=None，不过当数据在每个点有多个观察值时，可能会产生奇怪的效果 1sns.relplot(x="timepoint", y="signal", estimator=None, kind="line", data=fmri) 有时候我们需要对同一个问题做重复测量并比较。那么seaborn也可以单独绘制 123sns.relplot(x="timepoint", y="signal", hue="region", units="subject", estimator=None, kind="line", data=fmri.query("event == 'stim'")) 线图通常用于可视化与实际日期和时间相关的数据。这些函数将原始格式的数据传递给底层matplotlib函数，因此它们可以利用matplotlib在刻度标签中格式化日期的能力。但是所有的格式化都必须在matplotlib层进行，您可以参考matplotlib文档来了解它是如何工作的： 12345fig = plt.figure(figsize=(8,6))df = pd.DataFrame(dict(time=pd.date_range("2017-1-1", periods=500), value=np.random.randn(500).cumsum()))g = sns.relplot(x="time", y="value", kind="line", data=df)g.fig.autofmt_xdate() # 当X轴是时间格式时，用此方法旋转避免重叠。 如果要检查变量多个分类的效果，最好将它放在列上分类。 1234sns.relplot(x="timepoint", y="signal", hue="event", style="event", col="subject", col_wrap=5, height=3, aspect=.75, linewidth=2.5, kind="line", data=fmri.query("region == 'frontal'")) 下篇文章，我们讨论seaborn中的线性关系可视化]]></content>
      <categories>
        <category>python</category>
        <category>可视化</category>
      </categories>
      <tags>
        <tag>可视化</tag>
        <tag>python</tag>
        <tag>seaborn</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[一个计算时间的脚本]]></title>
    <url>%2Fblogs%2Fc9a9ff25%2F</url>
    <content type="text"><![CDATA[因为之前的自动化的工作中几乎每个脚本都要在时间节点运行，比如每周的第一天，每月第一天和最后一天等等。这就要涉及到时间的计算，但是没有现成的包，只能自己写一个(╯‵□′)╯︵┻━┻。 用例这个脚本里包含了一般自动化报表会用到的时间节点。 时间节点 函数方法 今天 today 昨天 yesterday() 上个月是几月 last_month() 上月第一天 last_month_start() 上月最后一天 last_month_end() 上周第一天 last_week_start() 上周最后一天 last_week_end() 本周是今年第几周 weeknum 今天是本周第几天 wday 今天是本月第几天 mday 今天是本年第几天 yday 12345day1 = Someday(timestr="2019-03-01") # 指定今天的日期print(day1.today)print(day1.yesterday())print(day1.last_month())print(day1.last_month_start()) 2019-03-01 00:00:00 2019-02-28 2 2019-02-01 123456day2 = Someday(n=1) # 以实际今天为基点向前n天为指定的“今天”print(day2.today)print(day2.last_week_start())print(day2.last_week_end()print(day2.today_s)print(day2.weeknum) 2019-03-11 2019-03-04 2019-03-10 time.struct_time(tm_year=2019, tm_mon=3, tm_mday=11, tm_hour=0, tm_min=0, tm_sec=0, tm_wday=0, tm_yday=70, tm_isdst=-1) 11 源码123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101import timeimport datetimeimport calendarclass Someday: """ 自定义起始日期，然后从起始日期计算： 当天日期，昨天日期， 上月开始结束日期，上周开始结束日期， 本周是今年第几周，今天是本周第几天 参数设定： timestr: str,按照"2019-01-01"的格式填写 n: int,n=0 等于今天，1等于昨天，2等于前天，以此类推 **两个参数不能同时存在!!!** """ def __init__(self, timestr=None, n=None): """ timestr: str,按照"2019-01-01"的格式填写 n: int,n=0等于今天，1等于昨天，2等于前天，以此类推 ** 两个参数不能同时存在!!! ** """ if timestr is None: if n is None: time_str = datetime.date.today() else: time_str = (datetime.date.today() - datetime.timedelta(days=n)) else: if n is None: time_str = datetime.datetime.strptime(timestr, "%Y-%m-%d") else: time_str = datetime.datetime.strptime(timestr, "%Y-%m-%d") print("参数timestr和n不能同时使用!!!,否则默认使用timestr参数") self.today = time_str self.today_s = time_str.timetuple() # 输出今天的struct_time格式 self.year = self.today_s.tm_year # 今年年份 self.month = self.today_s.tm_mon # 本月是几月 self.mday = self.today_s.tm_mday # 今天是本月第几天 self.yday = self.today_s.tm_yday # 今天是今年第几天 self.wday = self.today_s.tm_wday # 今天是本周第几天 self.weeknum = self.today.isocalendar()[1] # 今周是今年第几周 def yesterday(self): """返回昨天的日期""" result = (self.today - datetime.timedelta(days=1)).strftime('%Y-%m-%d') return result def last_month(self): """返回上个月是几月""" if self.month == 1: result = 12 else: result = self.month - 1 return result def last_month_start(self): """返回上月的第一天""" month_l = self.last_month() if month_l == 12: year_l = self.year - 1 else: year_l = self.year result = datetime.date( year=year_l, month=month_l, day=1).strftime('%Y-%m-%d') return result def last_month_end(self): """返回上月最后一天""" month_l = self.last_month() if month_l == 12: year_l = self.year - 1 else: year_l = self.year mrange = calendar.monthrange(year_l, month_l)[1] result = datetime.date( year=year_l, month=month_l, day=mrange).strftime('%Y-%m-%d') return result def last_week_start(self): """返回上周第一天""" result = ( self.today - datetime.timedelta( days=self.today.weekday() + 7)).strftime("%Y-%m-%d") return result def last_week_end(self): """返回上周最后一天""" result = ( self.today - datetime.timedelta( days=self.today.weekday() + 1)).strftime("%Y-%m-%d") return result 通过两种指定“今天”的方式，可以计算出以任意一天为基点的相关日期。非常方便。如果你有更好的建议可以联系我。]]></content>
      <categories>
        <category>python</category>
        <category>自动化</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python数据可视化seaborn（二）—— 分布数据可视化]]></title>
    <url>%2Fblogs%2Ff31a11b%2F</url>
    <content type="text"><![CDATA[这篇文章是Python可视化seaborn系列的第二篇文章，本文将详解seaborn如何探索数据的分布。 1234567891011import numpy as npimport pandas as pdimport matplotlib.pyplot as pltimport seaborn as sns% matplotlib inlinesns.set(context='notebook',font='simhei',style='whitegrid')# 设置风格尺度和显示中文import warningswarnings.filterwarnings('ignore') # 不发出警告 单变量直方图 displotseaborn.distplot(a, bins=None, hist=True, kde=True, rug=False, fit=None, hist_kws=None, kde_kws=None, rug_kws=None, fit_kws=None, color=None, vertical=False, norm_hist=False, axlabel=None, label=None, ax=None) bins → 箱数 hist、ked、rug → bool,是否显示箱/密度曲线/数据分布 norm_hist → 直方图是否按照密度来显示，如果为False,显示计数 {hist，kde，rug，fit} _kws：字典，对应部分的各种参数。 vertical → 是否水平显示 fit → 可结合scipy库在图像上做拟合 label → 图例 axlabel → x轴标注 123456789101112131415# 直方图from scipy.stats import norm #使用直方图和最大似然高斯分布拟合绘制分布rs = np.random.RandomState(50) # 设置随机数种子s = pd.Series(rs.randn(100)*100)plt.figure(figsize=(8,4))sns.distplot(s, bins=10, hist=True, kde=False, norm_hist=False, rug=True, vertical=False,label='distplot', axlabel='x轴',hist_kws=&#123;'color':'y','edgecolor':'k'&#125;, fit=norm)# 用标准正态分布拟合plt.legend()plt.grid(linestyle='--')plt.show() 12345678910plt.figure(figsize=(8,4))sns.distplot(s,rug = True, rug_kws = &#123;'color':'b'&#125; , # 设置数据频率分布颜色 kde_kws=&#123;"color": "k", "lw": 2, "label": "KDE",'linestyle':'--'&#125;, # 设置密度曲线颜色，线宽，标注、线形 hist_kws=&#123;"histtype": "step", "linewidth": 2,"alpha": 1, "color": "g"&#125;) # 设置箱子的风格、线宽、透明度、颜色 # 风格包括：'bar', 'barstacked', 'step', 'stepfilled'plt.show() 核密度估计图 kdeplot核密度估计的步骤： 每一个观测附近用一个正态分布曲线近似 叠加所有观测的正态分布曲线 归一化 seaborn.kdeplot（data，data2 = None，shade = False，vertical = False，kernel =’gau’，bw =’scott’，gridsize = 100，cut = 3，clip = None，legend = True，cumulative = False，shade_lowest = True，cbar = False，cbar_ax =无，cbar_kws =无，ax =无，** kwargs ） shade: 如果为True，则用颜色填充KDE曲线下方的区域（或者在数据为双变量时用颜色填充的轮廓） kernel: {‘gau’|‘cos’|‘biw’|‘epa’|‘tri’|‘triw’} 用于拟合的核，双变量值能用高斯核（gau） bw: {‘scott’|’silverman’|标量|一对标量} 确定核的大小，近似理解为拟合程度，bw越大，曲线越平缓。 gridsize：int, 网格中的离散点数 cumulative ：是否绘制累积分布 cbar：参数若为True，则会添加一个颜色条(颜色条在双变量kde图像中才有) 12345678# 单个样本数据密度分布图plt.figure(figsize=(8,4))sns.kdeplot(s,label='auto')sns.kdeplot(s,bw=10, label="bw: 10",linewidth = 1.5)sns.kdeplot(s,bw=100, label="bw: 100",linestyle = '--',linewidth = 1.5)# bw → 也可以类似看做直方图的箱数，数越大，箱子越多，刻画的越精确。plt.show() 123sns.kdeplot(s, label="累积图",color='k',cumulative=True, linestyle = '--',linewidth = 2)plt.show() 核密度各级图不但能绘制单个变量的，也能绘制双变量！！！ 123456789101112131415161718192021# 2、密度图 - kdeplot()# 两个样本数据密度分布图rs = np.random.RandomState(2) # 设定随机数种子df = pd.DataFrame(rs.randn(100,2), columns = ['A','B'])fig = plt.figure(figsize=(10,6))sns.kdeplot(df['A'],df['B'], cbar = True, # 是否显示颜色图例 shade = True, # 是否填充 cmap = 'Reds_r', # 设置调色盘 shade_lowest=True, # 最外围颜色是否显示 n_levels = 10, # 曲线个数（越大，越密集） bw = .3 )# 两个维度数据生成曲线密度图，以颜色作为密度衰减显示sns.rugplot(df['A'], color="g", axis='x',alpha = 0.5)sns.rugplot(df['B'], color="k", axis='y',alpha = 0.5)# 注意设置x，y轴 双变量jointplotseaborn.jointplot（x，y，data = None，kind =’scatter’，color = None，height = 6，ratio = 5，space = 0.2，dropna = True，xlim = None，ylim = None，joint_kws = None，marginal_kws =None，annot_kws =None，** kwargs ） 该函数是JoinGrid类的一个轻量级界面，如果想更加灵活的绘制，可以使用JoinGrid函数 kind: 设置类型：“scatter”、“reg”、“resid”、“kde”、“hex” height: int, 图像大小（图像自动调整为正方形） radio: int, 主图与边缘图的高度比 space: # 设置主图和边缘图的间距 {x，y} lim ：在绘图之前设置轴限制 {joint，marginal，annot} _kws：dicts 绘图组件的其他关键字参数 123456789101112131415# 散点图 + 边缘直方图tips = sns.load_dataset("tips")sns.jointplot(x='total_bill', y='tip', # 设置xy轴，显示columns名称 data=tips, # 设置数据 color = 'k', # 设置颜色 s = 50, edgecolor="w",linewidth=1, # 设置散点大小、边缘线颜色及宽度(只针对scatter） kind = 'scatter', space = 0.2, # 设置散点图和布局图的间距 height = 7, ratio = 5, # 散点图与布局图高度比，整型 marginal_kws=dict(bins=20, rug=True) # 设置柱状图箱数，是否设置rug )plt.show() seaborn会直接给出变量的皮尔逊相关系数和P值pearson相关系数计算： $\rho_{X,Y} = \frac{cov(X,Y)} {\sigma_X \sigma_Y}$ p：样本间的差异由抽样误差所致的概率小于p.p-value 12345678910# 回归图 + 边缘直方图with sns.axes_style("ticks"): sns.jointplot(x='total_bill', y='tip',data = tips, kind="hex", color="r", # 主图为六角箱图 height=6,space=0.1, joint_kws=dict(gridsize=20,edgecolor='w'), # 主图参数设置 marginal_kws=dict(bins=20,color='g', hist_kws=&#123;'edgecolor':'k'&#125;), # 边缘图设置 annot_kws=dict(stat='r',fontsize=15)) # 修改统计注释 123456789101112# 密度图rs = np.random.RandomState(15)df = pd.DataFrame(rs.randn(300,2),columns = ['A','B'])# 创建数据with sns.axes_style("white"):# 设置当前图的样式 g = sns.jointplot(x=df['A'], y=df['B'],data = df, kind="kde", color="k",shade_lowest=False)# 创建密度图 g.plot_joint(plt.scatter,c="r", s=30, linewidth=1, marker="+")# 添加散点图 JointGrid前面讲过jointplot其实是JoinGrid的一个封装，要想有更灵活的设置，可以使用JoinGrid类 __init__（x，y，data = None，height = 6，ratio = 5，space = 0.2，dropna = True，xlim = None，ylim = None） 方法： plot（joint_func，marginal_func ,annot_func)→ 绘制完整的图形 plot_joint（func，** kwargs）→ 绘制双变量图形 plot_marginals（func，** kwargs）→ 绘制边缘单变量图形 savefig（* args，** kwargs）→ 保存 set_axis_labels（[xlabel，ylabel]）→ 在双变量轴上设置轴标签。 123456789101112131415161718192021222324# 可拆分绘制的散点图# plot_joint() + ax_marg_x.hist() + ax_marg_y.hist()sns.set_style("white")# 设置风格g = sns.JointGrid(x="total_bill", y="tip", data=tips, height=7)# 创建一个绘图表格区域，设置好x、y对应数据g.plot_joint(sns.kdeplot, color ='m', edgecolor = 'white') # 设置框内图表，scatterg.ax_marg_x.hist(tips["total_bill"], color="b", alpha=.6, edgecolor='k',bins=np.arange(0, 60, 3))# 设置x轴直方图，注意bins是数组g.ax_marg_y.hist(tips["tip"], color="r", alpha=.6, orientation="horizontal",edgecolor='k', bins=np.arange(0, 12, 1))# 设置y轴直方图，注意需要orientation参数from scipy import statsg.annotate(stats.spearmanr , fontsize=16, loc='best')# 设置标注，可以为pearsonr，spearmanr，或者是自定义的函数plt.grid(linestyle = '--') 12345678910111213# 可拆分绘制的散点图# plot_joint() + plot_marginals()g = sns.JointGrid(x="total_bill", y="tip", data=tips,height=6.5,ratio=6)# 创建一个绘图表格区域，设置好x、y对应数据g = g.plot_joint(plt.scatter,color="g", s=50, edgecolor="white") # 绘制散点图plt.grid(linestyle = '--') # 设置网格线g.plot_marginals(sns.distplot, kde=True, hist_kws=&#123;'color':'g','edgecolor':'k'&#125;) # 设置边缘图rsquare = lambda a, b: stats.pearsonr(a, b)[0] ** 2 # 自定义统计函数g = g.annotate(rsquare, template="&#123;stat&#125;: &#123;val:.2f&#125;", stat="$R^2$", loc="upper left", fontsize=16) # 设置注释 123456789101112# 1、综合散点图 - JointGrid()# 可拆分绘制的散点图# plot_joint() + plot_marginals()# kde - 密度图g = sns.JointGrid(x="total_bill", y="tip", data=tips,space=0)# 创建一个绘图表格区域，设置好x、y对应数据g = g.plot_joint(sns.regplot) # 绘制密度图plt.grid(linestyle = '--')g.plot_marginals(sns.distplot, color="r",bins=20,hist_kws=&#123;'edgecolor':'k'&#125;) # 绘制x，y轴密度图g.annotate(stats.pearsonr) 探索两两变量之间的关系通常我们的数据并不是只有一个或者两个变量，那么对于多个变量，我们常需要探索两两变量之间的分布及关系这是我们就需要使用pairplot函数或者是PairGrid类 pairplotseaborn.pairplot（data，hue = None，hue_order = None，palette = None，vars = None，x_vars = None，y_vars = None，kind =’scatter’，diag_kind =’auto’，markers = None，s = 2.5，aspect = 1，dropna = True，plot_kws = None，diag_kws = None，grid_kws = None） hue: string(变量名) ： 颜色将按照指定的变量分类 hue_order ： list 设置调色板色调变量级别 palette ： 调色板 vars : list 变量名称列表，否则使用所有数值型变量的列 markers: 点样式 12345678910111213141516171819# 2、矩阵散点图 - pairplot()# sns.set_style("white")# 设置风格iris = sns.load_dataset("iris")print(iris.head())# 读取鸢尾花数据sns.pairplot(iris, kind = 'scatter', # 散点图/回归分布图 &#123;‘scatter’, ‘reg’&#125; diag_kind="hist", # 设置对角线图直方图/密度图 &#123;‘hist’, ‘kde’&#125; hue="species", # 按照某一字段进行分类 palette="husl", # 设置调色板 markers=["o", "s", "D"], # 设置不同系列的点样式（这里根据参考分类个数） height = 2, # 图表大小 plot_kws=&#123;'s':20&#125;, # 设置点大小 diag_kws=&#123;'edgecolor':'w'&#125;) # 设置对角线直方图样式plt.show() sepal_length sepal_width petal_length petal_width species 0 5.1 3.5 1.4 0.2 setosa 1 4.9 3.0 1.4 0.2 setosa 2 4.7 3.2 1.3 0.2 setosa 3 4.6 3.1 1.5 0.2 setosa 4 5.0 3.6 1.4 0.2 setosa 123456# 2、矩阵散点图 - pairplot()# 其他参数设置sns.pairplot(iris, kind="reg",hue='species', # 设置回归图形 diag_kind='kde',palette='hls', # 设置对角线图类型及调色盘 diag_kws=dict(shade=True),height=2) PairGrid相当于jointplot 和 JointGrid的关系，PairGrid 对矩阵散点图有着更为灵活的控制 __init__（data，hue = None，hue_order = None，palette = None，hue_kws = None，vars = None，x_vars = None，y_vars = None，diag_sharey = True，height = 2.5，aspect = 1，despine = True，dropna = True）方法： add_legend（[legend_data，title，label_order]）绘制一个图例，可能将其放在轴外并调整图形大小。 map_diag（func，** kwargs）：在每个对角线子图上绘制具有单变量函数的图。 map_lower（func，** kwargs）：在下对角线子图上绘制具有双变量函数的图。 map_upper（func，** kwargs）：在上对角线子图上绘制具有双变量函数的图 map_offdiag（func，** kwargs）：在非对角线子图上绘制具有双变量函数的图。 set（** kwargs）：在每个子图集Axes上设置属性。 123456789101112131415161718192021# 2、矩阵散点图 - PairGrid()# 可拆分绘制的散点图# map_diag() + map_offdiag()g = sns.PairGrid(iris,hue="species",palette = 'hls',height=2, vars = ['sepal_length','sepal_width','petal_length','petal_width'], # 可筛选 )# 创建一个绘图表格区域，设置好x、y对应数据，按照species分类g.map_diag(plt.hist, histtype = 'barstacked', # 可选：'bar', 'barstacked', 'step', 'stepfilled' linewidth = 1, edgecolor = 'w')# 对角线图表，plt.hist/sns.kdeplotg.map_offdiag(plt.scatter, edgecolor="w", s=40,linewidth = 1 # 设置点颜色、大小、描边宽度 )# 其他图表，plt.scatter/plt.bar...g.add_legend()# 添加图例 12345678# 2、矩阵散点图 - PairGrid()# 可拆分绘制的散点图# map_diag() + map_lower() + map_upper()g = sns.PairGrid(iris[iris['species']=='versicolor'])g.map_diag(sns.kdeplot, lw=3) # 设置对角线图表g.map_upper(sns.regplot, color = 'b') # 设置对角线上端图表g.map_lower(sns.kdeplot, cmap="Blues_d") # 设置对角线下端图表]]></content>
      <categories>
        <category>python</category>
        <category>可视化</category>
      </categories>
      <tags>
        <tag>可视化</tag>
        <tag>python</tag>
        <tag>seaborn</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python数据可视化seaborn（一）—— 整体样式与调色板]]></title>
    <url>%2Fblogs%2F4f39f027%2F</url>
    <content type="text"><![CDATA[很久之前对seaborn有过一些涉及但是没有深入探究，这次有趁着有数据可视化的需求，就好好学一学 Seaborn其实是在matplotlib的基础上进行了更高级的API封装，从而使得作图更加容易，在大多数情况下使用seaborn就能做出很具有吸引力的图，为数据分析提供了很大的便利性。但是应该把Seaborn视为matplotlib的补充，而不是替代物。 这次就从最基本的图标风格和调色板开始，学习seaborn。 图表风格（style）设置123456789# 利用 matplotlib创建一个正弦函数及图表def sinplot(flip=1): x = np.linspace(0, 14, 100)# fig = plt.figure(figsize=(10,6)) for i in range(1,7): plt.plot(x, np.sin(x + i * .5) * (7 - i) * flip)sinplot() sns.set() 设置样式参数seaborn.set（context =’notebook’，style =’darkgrid’，palette =’deep’，font =’sans-serif’，font_scale = 1，color_codes = True，rc = None) 123456sns.set(style='darkgrid',font_scale=1.5)# 利用此方法可以快速设置seaborn的默认风格，当然也可以添加参数设置其他风格# font_scale：float，单独的缩放因子可以独立缩放字体元素的大小。sinplot() set_style() 设置图标风格seaborn.set_style（style = None，rc = None ) 1234567891011121314# 切换seaborn图表风格# 风格选择包括："white", "dark", "whitegrid", "darkgrid", "ticks"# rc：dict，可选,参数映射以覆盖预设的seaborn样式字典中的值fig = plt.figure(figsize=(10, 8))ax1 = fig.add_subplot(2, 1, 1)sns.set_style('whitegrid',&#123;"xtick.major.size": 10, "ytick.major.size": 10&#125;)data = np.random.normal(size=(20,6)) + np.arange(6) / 2sns.boxplot(data=data)ax2 = fig.add_subplot(2, 1, 2)sinplot() sns.despine() 设置坐标轴seaborn.despine(fig=None, ax=None, top=True, right=True, left=False, bottom=False, offset=None, trim=False) 12345678910111213141516171819202122232425# 设置图表坐标轴sns.set(style='ticks',font_scale=1)# 设置风格fig = plt.figure(figsize=(10,12))plt.subplots_adjust(hspace=0.3) # 调整子图间距# 图表基本设置ax1 = fig.add_subplot(3, 1, 1)sinplot()sns.despine(ax=ax1)# 默认隐藏右边和上边的坐标轴ax2 = fig.add_subplot(3, 1, 2)sns.violinplot(data=data)sns.despine(ax=ax2,offset=&#123;'bottom':5,'left':10&#125;)# offset ：坐标轴是否分开偏移,正值向外侧移动，负值向内侧移动.可用字典单独对每个轴设置# trim: 当为True时，坐标轴两端限制在数据的最大最小值处ax3 = fig.add_subplot(3, 1, 3)sns.boxplot(data=data, palette='deep')sns.despine(ax=ax3,left=True, right= False, trim=True, offset=&#123;'bottom':10,'right':10&#125;)# top, right, left, bottom：布尔型，为True时不显示 sns.axes_style() 设置子图风格12345678910111213# 4、axes_style()# 设置局部图表风格，可学习和with配合的用法fig = plt.figure(figsize=(10,8))with sns.axes_style("darkgrid"): plt.subplot(211) sinplot()# 设置局部图表风格，用with做代码块区分sns.set_style("whitegrid")plt.subplot(212)sinplot()# 外部表格风格 设置显示比例尺度 set_context()seaborn.set_context（context = None，font_scale = 1，rc = None ) 1234567# 设置显示比例尺度# 选择包括：'paper', 'notebook', 'talk', 'poster'.这四个是预设的。不会影响整体样式。# 默认为notebooksns.set_context("notebook")sinplot()plt.grid(linestyle='--') 图标颜色设置 color_palette()sns.color_palette(palette=None, n_colors=None, desat=None) 我们选择颜色常常依据数据特征来选择，所以下面就从 分类：彼此间差异较大 连续：颜色按照顺序渐变 发散：中间颜色浅，两端颜色深 三个调色板来讲解color_palette()函数 分类调色板当你不用区分离散数据的顺序时，建议使用分类调色板 123456789# 默认6种颜色：deep, muted, pastel, bright, dark, colorblind# n_colors：int,调色板中的颜色数量# dasat:float，去饱和度0-1之间current_palette = sns.color_palette()sns.palplot(current_palette)# 当不带参数的调用将返回当前默认颜色循环中的所有颜色# 可以传入任何matplotlib支持的颜色 圆形调色系统当需要6中以上的颜色时，可以在圆形颜色空间中按均匀间隔画出颜色。 最常见的是使用hls颜色空间。 12sns.palplot(sns.color_palette('hls',8))# 颜色色块个数为8个 123data = np.random.normal(size=(10, 8)) + np.arange(8) / 2sns.boxplot(data=data,palette=sns.color_palette("hls", 8))plt.show() HLS色调空间：hls_palette([n_colors, h, l, s]) HUSL色调空间：husl_palette([n_colors, h, l, s]) 1234567# 设置亮度，饱和度# h - 第一个色调# l - 亮度# s - 饱和度sns.palplot(sns.husl_palette(8, l=.6, s=.7))# 这个看上去更舒服，更易区分 使用分类Color Brewer调色板另一个分类色板来源于Color Brewer（同样也具有连续色板和发散色板），它也同样存在于matplotlib colormaps中，但是并没有得到很好的处理。在Seaborn中，当你调用Color Brewer分类色板时，你总能得到离散的颜色，但是这意味着它们在某一点开始了循环。 Color Brewer网站的一个很好的功能是它提供了一些关于哪些调色板是色盲安全的指导 123# Color Brewer颜色设置sns.palplot(sns.color_palette("Paired",8))sns.palplot(sns.color_palette("Set1",10)) 使用xkcd颜色测量中的命名颜色xkcd包含了一系列命名RGB颜色。共954种颜色，您现在可以使用xkcd_rgb字典在seaborn中引用它们： 123plt.plot([0, 1], [0, 1], sns.xkcd_rgb["pale red"], lw=3)plt.plot([0, 1], [0, 2], sns.xkcd_rgb["medium green"], lw=3)plt.plot([0, 1], [0, 3], sns.xkcd_rgb["denim blue"], lw=3) 顺序调色板当数据范围从相对较低或不感兴趣的值到相对较高或有趣的值时，可以使用连续(顺序)调色板，在kdeplot()和heatmap()函数中常常会用到。 具有大色调偏移的色彩图往往会引入数据中不存在的不连续性，并且我们的视觉系统无法自然地将彩虹映射到诸如“高”或“低”的定量区别。结果是这些可视化最终更像是一个谜题，它们模糊了数据中的模式而不是揭示它们 所以对于顺序数据，最好使用色调最多相对微妙偏移的调色板，伴随着亮度和饱和度的大幅度变化。这种方法自然会吸引人们关注数据的相对重要部分 1234sns.palplot(sns.color_palette("Blues"))sns.palplot(sns.color_palette("Blues_r"))# 与matplotlib中一样，如果您希望反转亮度渐变，则可以为_r调色板名称添加后缀# 不是所有颜色都可以反转！！！ 顺序 cubehelix 调色板cubehelix调色板系统既能亮度线性变化同时也能色调变化的线性色板。这意味着当转换为黑白（用于打印）或由色盲个人查看时，色彩映射中的信息将被保留。 seaborn.cubehelix_palette（n_colors = 6，start = 0，rot = 0.4，gamma = 1.0，hue = 0.8，light = 0.85，dark = 0.15，reverse = False，as_cmap = False ） 12345678910111213# 按照线性增长计算，设置颜色sns.palplot(sns.color_palette("cubehelix", 8))sns.palplot(sns.cubehelix_palette(8, gamma=2))sns.palplot(sns.cubehelix_palette(8, start=.5, rot=-.75))sns.palplot(sns.cubehelix_palette(8, start=2, rot=0, dark=0, light=.95, reverse=True))# n_colors → 颜色个数# start → 值区间在[0,3]，开始颜色# rot → float,颜色旋转角度,可能是（-1,1）之间# gamma → 颜色伽马值，&gt;1 较亮，&lt;1 较暗# dark，light → 值区间0-1，颜色深浅# reverse → 布尔值，默认为False，由浅到深 自定义顺序调色板对于自定义顺序调色板的简单界面，您可以使用light_palette()或使用dark_palette()，都是由单一的颜色并生成从浅色或深色去饱和值到该颜色的渐变调色板。这些函数还伴随着启动交互式小部件以创建这些调色板的功能 seaborn.light_palette（color，n_colors = 6，reverse = False，as_cmap = False，input =’rgb’ ）seaborn.dark_palette（color，n_colors = 6，reverse = False，as_cmap = False，input =’rgb’ ） 12345678910# color: 十六进制代码，html颜色名称或input空间中的元组# input: &#123;'rgb'，'hls'，'husl'，xkcd'&#125;# 用于解释输入颜色的颜色空间。前三个选项适用于元组输入，后者适用于字符串输入sns.palplot(sns.light_palette("green"))# 按照green做浅色调色盘sns.palplot(sns.dark_palette('green', reverse=True))# 按照green做深色调色盘sns.palplot(sns.light_palette((260, 75, 60), input="husl"))sns.palplot(sns.dark_palette("muted purple", input="xkcd")) 发散的调色板第三类调色板称为“发散”。这些用于大低值和高值都很有趣的数据。数据中通常还有明确定义的中点。例如，如果要绘制某个基线时间点的温度变化，最好使用偏差色图来显示相对减少的区域和相对增加的区域。 同样重要的是要强调使用红色和绿色应该避免，因为大量潜在的观众将无法区分它们 seaborn.diverging_palette(h_neg, h_pos, s=75, l=50, sep=10, n=6,center=’light’, as_cmap=False) 12345678910111213# 创建分散颜色# h_neg, h_pos → 起始/终止颜色值# s → 值区间0-100，饱和度# l → 值区间0-100，亮度# n → 颜色个数# center → 中心颜色为浅色还是深色“light”，“dark”,默认为light# Color Brewer库带有一组精心挑选的发散色图sns.palplot(sns.color_palette("BrBG", 7))# 当然可以自己定制sns.palplot(sns.diverging_palette(145, 280, s=85, l=25, n=7)) 1234plt.figure(figsize = (8,6))x = np.arange(16).reshape(4, 4)cmap = sns.diverging_palette(200, 20, sep=16, as_cmap=True)sns.heatmap(x, cmap=cmap) 选择调色板 choose_colorbrewer_palette()您可以使用该choose_colorbrewer_palette()函数来播放各种颜色选项，如果希望返回值是可以传递给seaborn或matplotlib函数的colormap对象，则可以将as_cmap参数设置为True seaborn.choose_colorbrewer_palette(data_type, as_cmap=False) 1234sns.choose_colorbrewer_palette('q')# sequential：顺序，可以用 s 来代替# diverging：发散, 可以用 d 来代替# qualitative：分类, 可以用 q 来代替 123456789101112131415161718192021# Color Brewer的颜色图：# Accent, Accent_r, Blues, Blues_r, BrBG, BrBG_r, BuGn, BuGn_r, BuPu,# BuPu_r, CMRmap, CMRmap_r, Dark2, Dark2_r, GnBu, GnBu_r, Greens, Greens_r, Greys,#Greys_r, OrRd, OrRd_r, Oranges, Oranges_r, PRGn, PRGn_r,# Paired, Paired_r, Pastel1, Pastel1_r, Pastel2, Pastel2_r, PiYG, PiYG_r, PuBu, PuBuGn,#PuBuGn_r, PuBu_r, PuOr, PuOr_r, PuRd, PuRd_r, Purples,# Purples_r, RdBu, RdBu_r, RdGy, RdGy_r, RdPu, RdPu_r, RdYlBu, RdYlBu_r, RdYlGn, RdYlGn_r,# Reds, Reds_r, Set1, Set1_r, Set2, Set2_r, Set3,# Set3_r, Spectral, Spectral_r, Wistia, Wistia_r, YlGn, YlGnBu, YlGnBu_r, YlGn_r, YlOrBr,# YlOrBr_r, YlOrRd, YlOrRd_r, afmhot, afmhot_r,# autumn, autumn_r, binary, binary_r, bone, bone_r, brg, brg_r, bwr, bwr_r, cool, cool_r,# coolwarm, coolwarm_r, copper, copper_r, cubehelix,# cubehelix_r, flag, flag_r, gist_earth, gist_earth_r, gist_gray, gist_gray_r, gist_heat,# gist_heat_r, gist_ncar, gist_ncar_r, gist_rainbow,# gist_rainbow_r, gist_stern, gist_stern_r, gist_yarg, gist_yarg_r, gnuplot, gnuplot2,# gnuplot2_r, gnuplot_r, gray, gray_r, hot, hot_r, hsv,# hsv_r, icefire, icefire_r, inferno, inferno_r, jet, jet_r, magma, magma_r, mako,# mako_r, nipy_spectral, nipy_spectral_r, ocean, ocean_r,# pink, pink_r, plasma, plasma_r, prism, prism_r, rainbow, rainbow_r, rocket, rocket_r,# seismic, seismic_r, spectral, spectral_r, spring,# spring_r, summer, summer_r, terrain, terrain_r, viridis, viridis_r, vlag, vlag_r, winter, winter_r 设置默认的调色板类似于color_palette()。set_palette()接受相同的参数，但它会更改默认的matplotlib参数，以便将调色板应用于所有绘图。 1234567891011121314# 设置调色板后，绘图创建图表sns.set_style("whitegrid")fig = plt.figure(figsize=(8,6))# 设置风格with sns.color_palette("PuBuGn_d"): plt.subplot(211) sinplot()sns.set_palette("husl")plt.subplot(212)sinplot()# 绘制系列颜色]]></content>
      <categories>
        <category>python</category>
        <category>可视化</category>
      </categories>
      <tags>
        <tag>可视化</tag>
        <tag>python</tag>
        <tag>seaborn</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python利用openpyxl来操作Excel（一）]]></title>
    <url>%2Fblogs%2F72901e2%2F</url>
    <content type="text"><![CDATA[最近一直在做项目里的自动化的工作，为了是从繁琐重复的劳动中挣脱出来，把精力用在数据分析上。自动化方面python是在好不过了，不过既然要提交报表，就不免要美观什么的。pandas虽然很强大，但是无法对Excel完全操作，现学vba有点来不及。于是就找到这个openpyxl包，用python来修改Excel，碍于水平有限，琢磨了两天，踩了不少坑，好在完成了自动化工作（以后起码多出来几个小时，美滋滋）。 在这里写下这两天的笔记和踩得坑，方面新手躲坑，也供自己日后查阅。如有问题，还请见谅并指出，多谢。 123456from openpyxl import load_workbookfrom openpyxl.styles import colors, Font, Fill, NamedStylefrom openpyxl.styles import PatternFill, Border, Side, Alignment# 加载文件wb = load_workbook('./5a.xlsx') workbook： 工作簿，一个excel文件包含多个sheet。 worksheet：工作表，一个workbook有多个，表名识别，如“sheet1”,“sheet2”等。 cell： 单元格，存储数据对象 文章所用表格为： 操作sheet12345678# 读取sheetnameprint('输出文件所有工作表名：\n', wb.sheetnames)ws = wb['5a']# 或者不知道名字时sheet_names = wb.sheetnamesws2 = wb[sheet_names[0]] # index为0为第一张表print(ws is ws2) 输出文件所有工作表名： [&apos;5a&apos;] True 1234# 修改sheetnamews.title = '5a_'print('修改sheetname：\n', wb.sheetnames) 修改sheetname： [&apos;5a_&apos;] 12345678# 创建新的sheet# 创建的新表必须要赋值给一个对象，不然只有名字但是没有实际的新表ws4 = wb.create_sheet(index=0, title='newsheet')# 什么参数都不写的话，默认插入到最后一个位置且名字为sheet,sheet1...按照顺序排列ws5 = wb.create_sheet()print('创建新的sheet:\n', wb.sheetnames) 创建新的sheet: [&apos;newsheet&apos;, &apos;5a_&apos;, &apos;Sheet&apos;] 123# 删除sheetwb.remove(ws4) # 这里只能写worksheet对象，不能写sheetnameprint('删除sheet：\n', wb.sheetnames) 删除sheet： [&apos;5a_&apos;, &apos;Sheet&apos;] 1234567# 修改sheet选项卡背景色，默认为白色，设置为RRGGBB模式ws.sheet_properties.tabColor = "FFA500"# 读取有效区域print('最大列数为：', ws.max_column)print('最大行数为：', ws.max_row) 最大列数为： 5 最大行数为： 17 1234567# 插入行和列ws.insert_rows(1) # 在第一行插入一行ws.insert_cols(2, 4) # 从第二列开始插入四列# 删除行和列ws.delete_cols(6, 3) # 从第六列（F列）开始，删除3列即（F:H）ws.delete_rows(3) # 删除第三行 单元格操作12345# 读取c = ws['A1']c1 = ws.cell(row=1, column=2)print(c, c1)print(c.value, c1.value) &lt;Cell &apos;5a_&apos;.A1&gt; &lt;Cell &apos;5a_&apos;.B1&gt; dth_title Province 1234# 修改ws['A1'] = '景区名称'ws.cell(1, 2).value = '省份'print(c.value, c1.value) 景区名称 省份 1234567891011# 读取多个单元格cell_range = ws['A1':'D5']colC = ws['C']col_range = ws['C:D']row10 = ws[10]row_range = ws[5:10]# 其返回的结果都是一个包含单元格的元组print(type(cell_range))for i in row10: print(i) # row10只有有效单元格 &lt;class &apos;tuple&apos;&gt; &lt;Cell &apos;5a_&apos;.A10&gt; &lt;Cell &apos;5a_&apos;.B10&gt; &lt;Cell &apos;5a_&apos;.C10&gt; &lt;Cell &apos;5a_&apos;.D10&gt; &lt;Cell &apos;5a_&apos;.E10&gt; 123456# 按照行列操作for row in ws.iter_rows(min_row=1, max_row=3, min_col=1, max_col=2): for cell in row: print(cell)# 也可以用worksheet.iter_col(),用法都一样 &lt;Cell &apos;5a_&apos;.A1&gt; &lt;Cell &apos;5a_&apos;.B1&gt; &lt;Cell &apos;5a_&apos;.A2&gt; &lt;Cell &apos;5a_&apos;.B2&gt; &lt;Cell &apos;5a_&apos;.A3&gt; &lt;Cell &apos;5a_&apos;.B3&gt; 1234567891011121314# 合并单元格ws.merge_cells('F1:G1')ws['F1'] = '合并两个单元格'# 或者ws.merge_cells(start_row=2, start_column=6, end_row=3, end_column=8)ws.cell(2, 6).value = '合并三个单元格'# 取消合并单元格ws.unmerge_cells('F1:G1')# 或者ws.unmerge_cells(start_row=2, start_column=6, end_row=3, end_column=8)wb.save('./5a.xlsx')# 保存之前的操作,保存文件时，文件必须是关闭的！！！ 注意！！！，openpyxl对Excel的修改并不像是xlwings一样是实时的，他的修改是暂时保存在内存中的，所以当后面的修改例如我接下来要在第一行插入新的一行做标题，那么当我对新的A1单元格操作的时候，还在内存中的原A1(现在是A2)的单元格原有的修改就会被覆盖。所以要先保存，或者从一开始就计划好更改操作避免这样的事情发生。（别问我怎么知道的，都是泪o(╥﹏╥)o） 样式修改单个单元格样式12345678910111213141516171819202122232425262728293031323334353637383940wb = load_workbook('./5a.xlsx') # 读取修改后的文件ws = wb['5a_']# 我们来设置一个表头ws.insert_rows(1) # 在第一行插入新的一行ws.merge_cells('A1:E1') # 合并单元格a1 = ws['A1']ws['A1'] = '5A级风景区名单'# 设置字体ft = Font(name='微软雅黑', color='000000', size=15, b=True)"""name:字体名称color:颜色通常是RGB或aRGB十六进制值b(bold):加粗（bool）i(italic):倾斜(bool)shadow：阴影（bool）underline：下划线（‘doubleAccounting’, ‘single’, ‘double’, ‘singleAccounting’）charset:字符集(int)strike:删除线(bool)"""a1.font = ft# 设置文本对齐ali = Alignment(horizontal='center', vertical='center')"""horizontal:水平对齐('centerContinuous', 'general', 'distributed', 'left', 'fill', 'center', 'justify', 'right')vertical:垂直对齐（'distributed', 'top', 'center', 'justify', 'bottom'）"""a1.alignment = ali# 设置图案填充fill = PatternFill('solid', fgColor='FFA500')# 颜色一般使用十六进制RGB# 'solid'是图案填充类型，详细可查阅文档a1.fill = fill openpyxl.styles.fills模块参数文档 123456789101112131415161718192021# 设置边框bian = Side(style='medium', color='000000') # 设置边框样式"""style:边框线的风格&#123;'dotted','slantDashDot','dashDot','hair','mediumDashDot', 'dashed','mediumDashed','thick','dashDotDot','medium', 'double','thin','mediumDashDotDot'&#125;"""border = Border(top=bian, bottom=bian, left=bian, right=bian)"""top（上）,bottom（下）,left（左）,right（右）:必须是 Side类型diagonal: 斜线 side类型 diagonalDownd: 右斜线 booldiagonalDown: 左斜线 bool"""# a1.border = borderfor item in ws['A1:E1'][0]: # 去元组中的每一个cell更改样式 item.border = borderwb.save('./5a.xlsx') # 保存更改 再次注意！！！： 不能使用 a1.border = border，否则只会如下图情况，B1：E1单元格没有线。我个人认为是因为线框涉及到相邻单元格边框的改动所以需要单独对每个单元格修改才行。 不能使用ws[&#39;A1:E1&#39;].border = border,由前面的内容可知，openpyxl的多个单元格其实是一个元组，而元组是没有style的方法的,所以必须一个一个改！！其实官方有其他办法，后面讲。 按列或行设置样式12345678910111213141516171819202122232425262728293031323334353637383940# 现在我们对整个表进行设置# 读取wb = load_workbook('./5a.xlsx')ws = wb['5a_']# 读取数据表格范围rows = ws.max_rowcols = ws.max_column# 字体font1 = Font(name='微软雅黑', size=11, b=True)font2 = Font(name='微软雅黑', size=11)# 边框line_t = Side(style='thin', color='000000') # 细边框line_m = Side(style='medium', color='000000') # 粗边框border1 = Border(top=line_m, bottom=line_t, left=line_t, right=line_t)# 与标题相邻的边设置与标题一样border2 = Border(top=line_t, bottom=line_t, left=line_t, right=line_t)# 填充fill = PatternFill('solid', fgColor='CFCFCF')# 对齐alignment = Alignment(horizontal='center', vertical='center')# 将样式打包命名sty1 = NamedStyle(name='sty1', font=font1, fill=fill, border=border1, alignment=alignment)sty2 = NamedStyle(name='sty2', font=font2, border=border2, alignment=alignment)for r in range(2, rows+1): for c in range(1, cols): if r == 2: ws.cell(r, c).style = sty1 else: ws.cell(r, c).style = sty2wb.save('./5a.xlsx') 对于，设置标题样式，其实官方也给出了一个自定义函数,设定范围后，范围内的单元格都会合并，并且应用样式，就像是单个cell一样。在这里就不多赘述了，有兴趣的可以看看。很实用。]]></content>
      <categories>
        <category>python</category>
        <category>自动化</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>Excel</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python时间序列基础（一）]]></title>
    <url>%2Fblogs%2F3ccb9cc8%2F</url>
    <content type="text"><![CDATA[Pyhton——时间模块详解 Python中提供了多个用于对日期和时间进行操作的内置模块：time模块、datetime模块和calendar模块。其中time模块是通过调用C库实现的，所以有些方法在某些平台上可能无法调用，但是其提供的大部分接口与C标准库time.h基本一致。time模块相比，datetime模块提供的接口更直观、易用，功能也更加强大。我们先看关于表示时间的几种方法 UTC time 世界协调时，又称格林尼治时间，世界标准时。与UTC对应各个时区的localtime,北京东八区比UTC早8小时，所以用UTC+8表示 epoch time 表示时间开始的起点；它是一个特定的时间，不同平台上这个时间点的值不太相同，对于Unix而言，epoch time为 1970-01-01 00:00:00 UTC timestamp(时间戳) 也称为Unix时间 或 POSIX时间；它是一种时间表示方式，表示从格林尼治时间1970年1月1日0时0分0秒开始到现在所经过的毫秒数，其值为float类型。 但是有些编程语言的相关方法返回的是秒数（Python就是这样），这个需要看方法的文档说明。需要说明的是时间戳是个差值，其值与时区无关。 元组（struct_time） struct_time元组共有9个元素，返回struct_time的函数主要有gmtime()，localtime()，strptime()。 time模块下面我们通过几个常用的实例详细介绍struct_time 中的属性 1234567891011import time# time.localtime() :将一个时间戳转换为当前时区的struct_timetime.localtime()#可以从结果中看到里面有9个元素# tm_wday=2 代表周二# tm_yday=73 代表一年中的第73天# tm_isdst=0 代表是否是夏令时，可取0,1，-1 取不同值可能会影响性能 time.struct_time(tm_year=2018, tm_mon=3, tm_mday=14, tm_hour=0, tm_min=24, tm_sec=59, tm_wday=2, tm_yday=73, tm_isdst=0) 12345678t = time.time() #返回当前时间的时间戳print(t)print('-------')time.sleep(1) #线程推迟指定的时间运行，单位为秒。print('hello,一秒后输出') 1520959413.8214176 ------- hello,一秒后输出 1234567t = time.gmtime()#将一个时间戳转换为UTC时区（0时区）的struct_time。print(t)print('------------')t1 = time.mktime(time.localtime()) #将一个struct_time 转化为时间戳print(t1) time.struct_time(tm_year=2018, tm_mon=3, tm_mday=13, tm_hour=16, tm_min=43, tm_sec=19, tm_wday=1, tm_yday=72, tm_isdst=0) ------------ 1520959399.0 1234567891011t = time.asctime()print(t)# 把一个表示时间的元组或者struct_time表示为这种形式：# 'Sun Jun 20 23:21:05 1993'。如果没有参数，将会将time.localtime()作为参数传入。print('----------')t1 = time.ctime()print(t1)#把一个时间戳（按秒计算的浮点数）转化为time.asctime()的形式。#如果参数未给或者为None的时候，将会默认time.time()为参数。它的作用相当于time.asctime(time.localtime(secs))。 Wed Mar 14 00:44:22 2018 ---------- Wed Mar 14 00:44:22 2018 1234567891011print(time.strftime('%Y-%m-%d',time.localtime()))'''返回字符串表示的当地时间。 把一个代表时间的元组或者struct_time（如由time.localtime()和time.gmtime()返回）转化为格式化的时间字符串，格式由参数format决定。如果未指定，将传入time.localtime()。如果元组中任何一个元素越界，就会抛出ValueError的异常。函数返回的是一个可读表示的本地时间的字符串。 参数：format：格式化字符串t ：可选的参数是一个struct_time对象''' 2018-03-14 格式化字符 字符含义 %a 本地（locale）简化星期名称 %A 本地完整星期名称 %b 本地简化月份名称 %B 本地完整月份名称 %c 本地相应的日期和时间表示 %d 一个月中的第几天（01 - 31） %H 一天中的第几个小时（24小时制，00 - 23） %I 第几个小时（12小时制，01 - 12） %j 一年中的第几天（001 - 366） %m 月份（01 - 12） %M 分钟数（00 - 59） %p 本地am或者pm的相应符(“%p”只有与“%I”配合使用才有效果) %S 秒（01 - 61）(文档中强调确实是0 - 61，而不是59，闰年秒占两秒) %U 一年中的星期数。（00 - 53星期天是一个星期的开始。）第一个星期天之前的所有天数都放在第0周。 %w 一个星期中的第几天（0 - 6，0是星期天） %W 和%U基本相同，不同的是%W以星期一为一个星期的开始。 %x 本地相应日期 %X 本地相应时间 %y 去掉世纪的年份（00 - 99） %Y 完整的年份 %Z 时区的名字（如果不存在为空字符） %% ‘%’字符 当使用strptime()函数时，只有当在这年中的周数和天数被确定的时候%U和%W才会被计算 综上，time模块总共有三种时间表达方式： timestamp 时间戳 tuple 或者 struct_time 格式化字符串 更多相关请查阅 time模块官方文档 datetime模块datetime是基于time模块封装的，是date和time模块的合集，但是执行效率略低。datetime有两个常量，MAXYEAR和MINYEAR，分别是9999和1。datetime里有四个重要的类： date ：表示日期，年月日 datetime ：表示日期时间，年月日时分秒 time ：表示时间，时分秒 timedelta ：表示时间间隔 datetime的date类123456789101112131415# datetime.date（year,month,day）: 返回 year-month-day# import datetime from datetime import datetoday = datetime.date.today() # datetime.date.today 返回今日print(today,type(today))# 输出格式为 date 类print(str(today),type(str(today)))t = datetime.date(2016,1,22)print(t)# (年，月，日) → 直接得到当时日期 2018-03-14 &lt;class &apos;datetime.date&apos;&gt; 2018-03-14 &lt;class &apos;str&apos;&gt; 2016-01-22 datetime的time类time类由hour小时、minute分钟、second秒、microsecond毫秒和tzinfo五部分组成 12345678# datetime.timet1 =datetime.time(2,22,33,9)print(t1,type(t1))t2 = t1.strftime('%H:%M:%S')print(t2,type(t2)) # 把一个datetime.time 类 转化为 str 02:22:33.000009 &lt;class &apos;datetime.time&apos;&gt; 02:22:33 &lt;class &apos;str&apos;&gt; datetime的datetime类datetime类其实是可以看做是date类和time类的合体，其大部分的方法和属性都继承于这二个类 1234567891011121314# datetime.datetime: datetime对象now = datetime.datetime.now()print(now,type(now))#输出datetime类t1 = datetime.datetime(2016,6,1)t2 = datetime.datetime(2014,1,1,12,44,33)print(t1)print(t2)# (年，月，日，时，分，秒)，至少输入年月日t2 - t1# 相减得到时间差 —— timedelta 2018-03-14 22:53:11.224884 &lt;class &apos;datetime.datetime&apos;&gt; 2016-06-01 00:00:00 2014-01-01 12:44:33 datetime.timedelta(-882, 45873) 时间差 timedelta12345678# datetime.timedelta 时间差today = datetime.datetime.today()yestoday = today + datetime.timedelta(-1) # -1 代表前一天print(today)print(yestoday)print(today - datetime.timedelta(7))# 时间差主要用作时间的加减法，相当于可被识别的时间“差值” 2018-03-13 21:35:31.238277 2018-03-12 21:35:31.238277 2018-03-06 21:35:31.238277 日期字符转换 parser.parse12345678910111213141516# parser.parse:日期字符转换from dateutil.parser import parsedate = '12-23-2018'date1 = '13/3/2018'print(parse(date),type(parse(date)))print(parse(date1))# 直接将几乎任何类似时间格式的str转化成datetime.datetimeprint(parse('2000-1-1'),'\n', parse('5/1/2014'),'\n', parse('5/1/2014', dayfirst = True),'\n', # 国际通用格式中，日在月之前，可以通过dayfirst来设置 parse('22/1/2014'),'\n', parse('Jan 31, 1997 10:45 PM'))# 各种格式可以解析，但无法支持中文 2018-12-23 00:00:00 &lt;class &apos;datetime.datetime&apos;&gt; 2018-03-13 00:00:00 2000-01-01 00:00:00 2014-05-01 00:00:00 2014-01-05 00:00:00 2014-01-22 00:00:00 1997-01-31 22:45:00]]></content>
      <categories>
        <category>python</category>
        <category>数据处理</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>时间序列</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[统计分析——描述统计之数据水平描述]]></title>
    <url>%2Fblogs%2Fcf1bfbe2%2F</url>
    <content type="text"><![CDATA[一组样本数据的数值特征一般来说可以从三个方面来描述： 数据的水平（也可以称之为集中趋势或位置度量），反映数据的数值大小 数据的差异，反映数据间的离散程度 数据的分布形状，反映数据分布的偏度和峰度 描述水平的统计量 数据水平是指数值大小，描述数据水平的统计量有平均数，分位数，众数,同时这几个统计量也可以用来描述数据的集中趋势度。 平均数简单平均数（simple mean）的公式： $$\bar{x} = \frac{x_{1}+x_{2}+x_{3}+…+x_{n}}{n} = \frac{\sum_{i=1}^{n}x_{i}}{n}$$ 加权平均数（weighted mean）：如果样本被分为K组，每组的组中值（组上限与下限的平均数）为m1,m2,..,mk表示各组的频数用f1,f2,…,fk表示，则样本平均数的计算公式为：$$ \bar{x} = \frac{m_{1}f_{1}+m_{2}f_{2}+m_{3}f_{3}+…+m_{k}f_{k}}{f_{1}+f_{2}+f_{3}+…+f_{k}} = \frac{\sum_{i=1}^{k}m_{i}f_{i}}{\sum_{i=1}^{k}f_{i}}$$ 一般来说，总体的平均数是无从得知的，因为无法得到总体是数据，所以我们常常从样本的平均数来推测总体的平均数。 R方法12345678910# 在 R中求简单平均数load(".\\tongjixue\\example\\ch3\\example3_1.RData") # 30名学生的成绩head(example3_1,5) # 展示前5名学生的成绩mean(example3_1$分数) # 求分数的平均值# mean(x, trim = 0, na.rm = FALSE, ...)# x - 向量# trim - 取值在0~0.5之间，例如trim=0.1,表示计算之前先排序，然后去掉前10%和后10%的数据，最后计算剩余数据的平均值# na.rm - 默认为FALSE，当为TRUE时，表示去掉数据中的缺失值。（当数据中有缺失值时无法计算） 分数 85 55 91 66 79 80 12345678910# 在 R中求加权平均数load(".\\tongjixue\\example\\ch3\\example3_2.RData") example3_2weighted.mean(example3_2$组中值, example3_2$人数)# weighted.mean(x, w,...,na.rm=FALSE)# x - 计算加权平均数的对象，对应公式中的 f# w - 相应的权数向量，相当于公式中的 m 分组组中值人数 60以下55 3 60—70 65 4 70—80 75 4 80—90 85 10 90—10095 9 81 python方法12345678import numpy as npimport pandas as pdfrom IPython.core.interactiveshell import InteractiveShellInteractiveShell.ast_node_interactivity = "all" # jupyter结果多行显示data_1 = np.array([[1, 2], [3, 4]]) # 矩阵data_2 = pd.DataFrame(data_1) # 数据框data_2 .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 0 1 0 1 2 1 3 4 123456789101112131415161718# 在 python中求简单平均数# 利用数据框自带的方法data_2.mean()# data.mean(axis=None, skipna=True)# axis - 默认为axis=None,即输出每列的平均值# skipna：布尔值，默认为True,计算结果时排除NA / null值# 使用 numpy的函数np.mean(data_1,axis=(1,0))# np.mean(data, axis=None)# axis - 默认为axis=None,如果为元组，则计算多轴上的平均值。例如（0,1）计算行和列的所有数据的平均值。 0 2.0 1 3.0 dtype: float64 2.5 123# 导入数据data_2 = pd.read_csv('.\\tongjixue\\example\\ch3\\example3_2.csv',engine='python')data_2 .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 分组 组中值 人数 0 60以下 55 3 1 60—70 65 4 2 70—80 75 4 3 80—90 85 10 4 90—100 95 9 123456789# 在python中求 加权平均数np.average(data_2['组中值'],weights=data_2['人数'])# numpy.average(a, axis=None, weights=None,...)# a - array_like,计算加权平均数的对象，对应公式中的 f# weights - array_like,相应的权数向量，相当于公式中的 m# axis - 默认为axis=None,如果为元组，则计算多轴上的平均值。 81.0 1234data = np.arange(6).reshape((3,2))datanp.average(data,axis=1, weights=[1./4, 3./4]) array([[0, 1], [2, 3], [4, 5]]) array([0.75, 2.75, 4.75]) 因为加权平均数是使用组中值来代表该组数据的，所以同一组数据，简单平均和加权平均结果不同，除非每组数据在组中值两侧成对称分布，故除非数据本来就是分组情况，一般都用简单平均求平均值。 分位数分位数代表数据水平的高低，常用的分位数有四分位数，中位数，百分位数 中位数 中位数是一组数据排序后位于中间位置的数值，用Me表示 中位数的特点是不受极端值的影响 四分位数 同中位数,将数据排序后位于1/4和3/4位置的数据。 百分位数 同四分位数，利用99个数据点将数据分为100份，百分位数提供了数据在最大值和最小值期间数据点分布信息。 R方法12345678910# 利用之前example3.1的学生成绩数据# 中位数median(example3_1$分数)# 四分位数quantile(example3_1$分数,probs = c(0.25,0.75))# R总计算分位数有9种方法，默认type=7。#百分位数quantile(example3_1$分数,probs=c(0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9)) 85 25% 75% 70.5 90 10% 20% 30% 40% 50% 60% 70% 80% 90% 60.4 66.8 74.1 81.6 85 86 89.3 91 92.3 python方法123data_3 = pd.read_csv('.\\tongjixue\\example\\ch3\\example3_1.csv',engine='python')np.percentile(data_3.分数,(25,50,75)) array([70.5, 85. , 90. ]) 求分位数在统计雪上有多种方法，当分位点位于两个数值中间时有不同的取值的方法，这个以后详细讨论。 众数一组数据众数数显频数最多的数值，用$M_{0}$表示，众数在数据量比较大时才有意义，众数可能不存在，也可能有2个或者多个。 R中没有直接求出众数的内置函数，所以需要自己写自定义众数函数 R方法1234567# 自定义函数getmode &lt;- function(x)&#123; y &lt;- sort(unique(x)) # 去重数值并排序 tab &lt;- tabulate(match(x,y)) # 比较x与y中的数值，并列出他们在y中的位置，在计算每个位置的频数放入对象tab中 y[tab==max(tab)] # 找出y中频数最多的元素&#125;getmode(example3_1$分数) 86 python方法在numpy或者pandas是没有求众数的方法的，但是我们可以利用scipy科学计算库中的mode函数 123456789from scipy.stats import modem0 = mode(data_3['分数'])[0][0]print(m0)# 或者利用numpy中的bincount()函数，此函数将数据按直方图统计count = np.bincount(data_3['分数'])m0_1 = np.argmax(count)print(m0_1) 86 86]]></content>
      <categories>
        <category>统计学习</category>
      </categories>
      <tags>
        <tag>统计学习</tag>
        <tag>特征分析</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[R语言数据处理——缺失值的识别与处理]]></title>
    <url>%2Fblogs%2F90825c4b%2F</url>
    <content type="text"><![CDATA[我们一般拿到的数据并不是完美标准的，并不能马上就能分析使用。常常我们需要对数据做处理，往往这也是最耗时的部分，而这其中缺失值的处理是非常重要的。 缺失值并非都是可以一概删除的无意义的记录。比如周二汽车行驶记录的缺失表明当天车主没有开车，如果长期周二不开车就可以推测车的车牌号是2或者7，因为周二限号嘛。再比如在学生卡的使用记录中，食堂用餐记录的大量缺失有可能是此同学经济条件较好，经常在食堂外用餐。但是天气的缺失纪录难以运用在天气的情况的统计中。以上种种，可以发现我们要结合实际分析场景，分析的目的来判断缺失值对于分析是否有意义。 缺失值的识别统计学家通常将缺失数据分为三类。它们都用概率术语进行描述，但思想都非常直观。我们用睡眠研究中对做梦时长的测量（有12个动物有缺失值）来依次阐述三种类型。 (1) 完全随机缺失：若某变量的缺失数据与其他任何观测或未观测变量都不相关，则数据为完全随机缺失（MCAR）。若12个动物的做梦时长值缺失不是由于系统原因，那么可认为数据是MCAR。注意，如果每个有缺失值的变量都是MCAR，那么可以将数据完整的实例看做是对更大数据集的一个简单随机抽样。 (2) 随机缺失： 若某变量上的缺失数据与其他观测变量相关，与它自己的未观测值不相关，则数据为随机缺失（MAR）。例如，体重较小的动物更可能有做梦时长的缺失值（可能因为较小的动物较难观察），“缺失”与动物的做梦时长无关，那么该数据就可以认为是MAR。此时，一旦你控制了体重变量，做梦时长数据的缺失与出现将是随机的。 (3) 非随机缺失：若缺失数据不属于MCAR或MAR，则数据为非随机缺失（NMAR）。例如，做梦时长越短的动物也更可能有做梦数据的缺失（可能由于难以测量时长较短的事件），那么数据可认为是NMAR。 大部分处理缺失数据的方法都假定数据是MCAR或MAR。此时，你可以忽略缺失数据的生成机制，并且（在替换或删除缺失数据后）可以直接对感兴趣的关系进行建模。当数据是NMAR时，想对它进行恰当地分析比较困难，你既要对感兴趣的关系进行建模，还要对缺失值的生成机制进行建模。（目前分析NMAR数据的方法有模型选择法和模式混合法 在R中，缺失值以符号NA（Not Available，不可用）表示。不可能出现的值（例如，被0除的结果）通过符号 NaN（Not a Number，非数值）来表示is.na()可以检测缺失值，将返回一个与元对象相同形状的布尔对象。 123456a &lt;- c(1,2,3,4,5,NA,6)is.na(a)a[5] == 5a[6] == NA # 在R中，缺失值是无法被比较的，所以逻辑运算符无法使用。a[1] + a[6] # 运算符也无法使用，必须要先删除缺失值才能计算。mean(a,na.rm = TRUE) #对a 求平均数，必须先去除缺失值。 FALSE FALSE FALSE FALSE FALSE TRUE FALSE TRUE &lt;NA&gt; &lt;NA&gt; 3.5 12345678# 加载VIM包自带的sleep睡眠数据集data(sleep, package='VIM')# 列出没有缺失值的行sleep[complete.cases(sleep),][1:3,]# 列出缺失值所在的行sleep[!complete.cases(sleep),][1:3,] BodyWgtBrainWgtNonDDreamSleepSpanGestPredExpDanger 2 1.0 6.66.3 2.0 8.3 4.5 42 3 1 3 52547.04603.02.1 1.8 3.9 69.0 624 3 5 4 6 10.6 179.59.1 0.7 9.8 27.0 180 4 4 4 BodyWgtBrainWgtNonDDreamSleepSpanGestPredExpDanger 16654.005712.0 NA NA 3.3 38.6 645 3 5 3 3 3.38 44.5 NA NA 12.5 14.0 60 1 1 1 4 0.92 5.7 NA NA 16.5 NA 25 5 2 3 12345sum(is.na(sleep$Dream)) # 该字段中总共有12个缺失值mean(is.na(sleep$Dream)) # 19%的实例在此变量上有缺失值mean(!complete.cases(sleep)) # 数据集中32%的实例包含一个或多个缺失值 12 0.193548387096774 0.32258064516129 1234567# mice包中的 md.pattern()函数可生成一个以矩阵或数据框形式展示缺失值模式的表格library("mice")md.pattern(sleep)# 第一行表述了“无缺失值”的模式（所有元素都为1）。第二行表述了“除了Span之外无缺失值”的模式。# 第一列表示各缺失值模式的实例个数，最后一列表示各模式中有缺失值的变量的个数# 最后一行给出每个变量的缺失值的个数 BodyWgtBrainWgtPredExpDangerSleepSpanGestDreamNonD 421 1 1 1 1 1 1 1 1 1 0 91 1 1 1 1 1 1 1 0 0 2 31 1 1 1 1 1 1 0 1 1 1 21 1 1 1 1 1 0 1 1 1 1 11 1 1 1 1 1 0 1 0 0 3 11 1 1 1 1 1 0 0 1 1 2 21 1 1 1 1 0 1 1 1 0 2 21 1 1 1 1 0 1 1 0 0 3 0 0 0 0 0 4 4 4 121438 12library("VIM")aggr(sleep, prop=FALSE, numbers=TRUE) 1234# matrixplot()函数可生成展示每个实例数据的图形。# 此处，数值型数据被重新转换到[0, 1]区间，并用灰度来表示大小：浅色表示值小，深色表示值大。默认缺失值为红色。matrixplot(sleep) 12345# marginplot()函数可生成一幅散点图，在图形边界展示两个变量的缺失值信息# 可以看到，做梦时长有4个缺失值，妊娠时长有12个缺失值，两个变量同时确实的实例个数为0（蓝色数字）marginplot(sleep[c("Gest","Dream")], pch=c(20), col=c("darkgray", "red", "blue")) 12345678# 探索缺失值之间的相关性x &lt;- as.data.frame(abs(is.na(sleep))) # 缺失值为1， 其他为0head(x, n=5)y &lt;- x[which(apply(x,2,sum)&gt;0)] # 按照列求和大于0的列 赋值给 ycor(y) # y 的相关性# 可以看到dream做梦时长和NonD（不做梦时长）有着强相关，两个变量常常同时缺失 BodyWgtBrainWgtNonDDreamSleepSpanGestPredExpDanger 0011000000 0000000000 0011000000 0011010000 0000000000 NonDDreamSleepSpanGest NonD 1.0000 0.9071 0.486 0.0152-0.142 Dream 0.9071 1.0000 0.204 0.0375-0.129 Sleep 0.4863 0.2037 1.000 -0.0690-0.069 Span 0.0152 0.0375-0.069 1.0000 0.198 Gest-0.1418-0.1287-0.069 0.1983 1.000 12345# 含缺失值变量与其他可观测变量间的关系cor(sleep, y, use="pairwise.complete.obs")# 在这个相关系数矩阵中，行为可观测变量，列为表示缺失的指示变量。你可以忽略矩阵中的警告信息和NA值# 从相关系数矩阵的第一列可以看到，体重越大（r = 0.227）、妊娠期越长（r =0.202）、睡眠暴露度越大（r = 0.245）的动物无梦睡眠的评分更可能缺失 Warning message in cor(sleep, y, use = &quot;pairwise.complete.obs&quot;): &quot;标准差为零&quot; NonDDreamSleepSpanGest BodyWgt 0.2268 0.2226 0.00168-0.0583 -0.0540 BrainWgt 0.1795 0.1632 0.00786-0.0792 -0.0733 NonD NA NA NA-0.0431 -0.0455 Dream-0.1890 NA -0.18895 0.1170 0.2277 Sleep-0.0802 -0.0802 NA 0.0964 0.0398 Span 0.0834 0.0598 0.00524 NA -0.0653 Gest 0.2024 0.0514 0.15970-0.1750 NA Pred 0.0476 -0.0683 0.20246 0.0231 -0.2010 Exp 0.2455 0.1274 0.26077-0.1929 -0.1929 Danger 0.0653 -0.0672 0.20888-0.0667 -0.2044 注意，表中的相关系数并不特别大，表明数据是MCAR的可能性比较小，更可能为MAR不过也绝不能排除数据是NMAR的可能性，因为你并不知道缺失数据背后对应的真实数据是怎么样的。比如，你不可能知道哺乳动物做梦时长与该变量数据缺失概率间的关系。当缺乏强力的外部证据时，我们通常假设数据是MCAR或者MAR 缺失值处理对于缺失值的处理我们常常根据数据的实际场景采用以下几种方法： 删除 插补法（用中值或均值插值，或者利用回归或者随机森林预测值插值） 作为特征保留 删除法行删除法12345678# 行删除newdata &lt;- sleep[complete.cases(sleep),] # 将没有缺失值的行储存为新数据newdata &lt;- na.omit(sleep) # 或者直接使用 na.omit 函数获得，两者结果一样。# options()允许用户设置和检查影响 R计算和显示结果的方式的各种全局选项options(digits=1) # 设置打印的有效数字为1cor(na.omit(sleep)) BodyWgtBrainWgtNonDDreamSleepSpanGestPredExpDanger BodyWgt 1.00 0.96-0.4 -0.07-0.3 0.47 0.71 0.10 0.4 0.26 BrainWgt 0.96 1.00-0.4 -0.07-0.3 0.63 0.73-0.02 0.3 0.15 NonD-0.39-0.39 1.0 0.52 1.0 -0.37-0.61-0.35-0.6 -0.53 Dream-0.07-0.07 0.5 1.00 0.7 -0.27-0.41-0.40-0.5 -0.57 Sleep-0.34-0.34 1.0 0.72 1.0 -0.38-0.61-0.40-0.6 -0.60 Span 0.47 0.63-0.4 -0.27-0.4 1.00 0.65-0.17 0.3 0.01 Gest 0.71 0.73-0.6 -0.41-0.6 0.65 1.00 0.09 0.6 0.31 Pred 0.10-0.02-0.4 -0.40-0.4 -0.17 0.09 1.00 0.6 0.93 Exp 0.41 0.32-0.6 -0.50-0.6 0.32 0.57 0.63 1.0 0.79 Danger 0.26 0.15-0.5 -0.57-0.6 0.01 0.31 0.93 0.8 1.00 表中的相关系数仅通过所有变量均为完整数据的42个动物计算得来。（注意代码cor(sleep,use=&quot;complete.obs&quot;)可生成同样的结果。） 123# 研究寿命和妊娠期对睡眠中做梦时长的影响，可应用行删除法的线性回归fit &lt;- lm(Dream ~ Span + Gest, data=na.omit(sleep))summary(fit) Call: lm(formula = Dream ~ Span + Gest, data = na.omit(sleep)) Residuals: Min 1Q Median 3Q Max -2.333 -0.915 -0.221 0.382 4.183 Coefficients: Estimate Std. Error t value Pr(&gt;|t|) (Intercept) 2.480122 0.298476 8.31 3.7e-10 *** Span -0.000472 0.013130 -0.04 0.971 Gest -0.004394 0.002081 -2.11 0.041 * --- Signif. codes: 0 &apos;***&apos; 0.001 &apos;**&apos; 0.01 &apos;*&apos; 0.05 &apos;.&apos; 0.1 &apos; &apos; 1 Residual standard error: 1 on 39 degrees of freedom Multiple R-squared: 0.167, Adjusted R-squared: 0.125 F-statistic: 3.92 on 2 and 39 DF, p-value: 0.0282 此处可以看到，动物妊娠期越短，做梦时长越长（控制寿命不变）；而控制妊娠期不变时，寿命与做梦时长不相关 插补法首先是简单插补法，就是利用特定值来插补，比如平均值，中位数，众数等。这种方法简单粗暴。只适合某些简单的场景中。 12345678# 利用中位数，平均数做简单插补library(Hmisc) # 导入Hmisc包newdata_2 &lt;- sleepnewdata_2$Dream &lt;- impute(newdata_2$Dream, mean) # 利用平均值插补，适用于正态分布newdata_2$Span &lt;- impute(newdata_2$Span, median) # 利用中位数插补，适用于偏态不严重时newdata_2$Gest &lt;- impute(newdata_2$Gest, "radom") # 随机数插补head(newdata_2,6) BodyWgtBrainWgtNonDDreamSleepSpanGestPredExpDanger 7e+035712 NA 2.0 3 39 645 3 5 3 1e+00 7 6 2.0 8 4 42 3 1 3 3e+00 44 NA 2.0 12 14 60 1 1 1 9e-01 6 NA 2.0 16 15 25 5 2 3 3e+034603 2 1.8 4 69 624 3 5 4 1e+01 180 9 0.7 10 27 180 4 4 4 然后是多重插补法， 多重插补（MI）是一种基于重复模拟的处理缺失值的方法。在面对复杂的缺失值问题时，MI是最常选用的方法。它利用蒙特卡洛方法来填补缺失值从而生成一组完整的数据集（通常是3到10个）。此时，标准的统计方法便可应用到每个模拟的数据集上，通过组合输出结果给出估计的结果 第一步，mice()函数首先从一个包含缺失数据的数据框开始，然后返回一个包含多个（默认为5个）完整数据集的对象。每个完整数据集都是通过对原始数据框中的缺失数据进行插补而生成的。 由于插补有随机的成分，因此每个完整数据集都略有不同。第二步，with()函数可依次对每个完整数据集应用统计模型（如线性模型 lm() 或广义线性模型 glm()）。第三步，pool()函数将这些单独的分析结果整合为一组结果。最终模型的标准误和p值都将准确地反映出由于缺失值和多重插补而产生的不确定性。 12345678910# 多重插补法# # options()允许用户设置和检查影响 R计算和显示结果的方式的各种全局选项options(digits=3) # 设置打印的有效数字为3library(mice) # 加载 mice包data(sleep, package="VIM") # 加载数据imp &lt;- mice(sleep, seed=1234)fit &lt;- with(imp, lm(Dream ~ Span + Gest)) # 利用线性回归，Dream为因变量，Span和Gest是自变量 用+号隔开pooled &lt;- pool(fit) # pooled：一个包含m个统计分析平均结果的列表对象。summary(pooled) iter imp variable 1 1 NonD Dream Sleep Span Gest 1 2 NonD Dream Sleep Span Gest 1 3 NonD Dream Sleep Span Gest 1 4 NonD Dream Sleep Span Gest 1 5 NonD Dream Sleep Span Gest 2 1 NonD Dream Sleep Span Gest 2 2 NonD Dream Sleep Span Gest 2 3 NonD Dream Sleep Span Gest 2 4 NonD Dream Sleep Span Gest 2 5 NonD Dream Sleep Span Gest 3 1 NonD Dream Sleep Span Gest 3 2 NonD Dream Sleep Span Gest 3 3 NonD Dream Sleep Span Gest 3 4 NonD Dream Sleep Span Gest 3 5 NonD Dream Sleep Span Gest 4 1 NonD Dream Sleep Span Gest 4 2 NonD Dream Sleep Span Gest 4 3 NonD Dream Sleep Span Gest 4 4 NonD Dream Sleep Span Gest 4 5 NonD Dream Sleep Span Gest 5 1 NonD Dream Sleep Span Gest 5 2 NonD Dream Sleep Span Gest 5 3 NonD Dream Sleep Span Gest 5 4 NonD Dream Sleep Span Gest 5 5 NonD Dream Sleep Span Gest estimatestd.errorstatisticdfp.value (Intercept) 2.628930.26086 10.078 53.3 3.80e-14 Span-0.003350.01233 -0.272 55.5 7.87e-01 Gest-0.004250.00154 -2.755 54.4 7.92e-03 你可以看到Span的回归系数不显著（p ≈ 0.08 ）， Gest的系数在 p &lt; 0.01的水平下很显著。若将这些结果与利用行删除法所得的结果对比，你会发现背离的结论相同。当控制寿命不变时，妊娠期与做梦时长有一个（统计）显著的、负相关的关系。行删除法基于42个有完整数据的动物，而此处的分析法基于整个数据集中全部62个动物的数据 12# 查看 imp汇总信息imp Class: mids Number of multiple imputations: 5 Imputation methods: BodyWgt BrainWgt NonD Dream Sleep Span Gest Pred &quot;&quot; &quot;&quot; &quot;pmm&quot; &quot;pmm&quot; &quot;pmm&quot; &quot;pmm&quot; &quot;pmm&quot; &quot;&quot; Exp Danger &quot;&quot; &quot;&quot; PredictorMatrix: BodyWgt BrainWgt NonD Dream Sleep Span Gest Pred Exp Danger BodyWgt 0 1 1 1 1 1 1 1 1 1 BrainWgt 1 0 1 1 1 1 1 1 1 1 NonD 1 1 0 1 1 1 1 1 1 1 Dream 1 1 1 0 1 1 1 1 1 1 Sleep 1 1 1 1 0 1 1 1 1 1 Span 1 1 1 1 1 0 1 1 1 1 Number of logged events: 5 it im dep meth out 1 1 2 Span pmm Sleep 2 2 5 Span pmm Sleep 3 2 5 Gest pmm Sleep 4 5 5 Span pmm Sleep 5 5 5 Gest pmm Sleep Number of multiple imputations：表示多重插补的数量，5次； Missing cells per column ： 表示每列变量缺失值包含的数量，如NonD包含14个缺失值； Imputation methods ： 可以看出对于有缺失值的变量采用了pmm（预测均值）的方法来插补。BodyWgt、BrainWgt、Pred、Exp、Danger没有进行插补，因为这些变量没有缺失数据； VisitSequence(如果有的话) ： 从左至右展示了插补的变量，这里进行插补的分别是sleep数据集中的第3到7列变量； PredictorMatrix ： 是预测变量矩阵，行代表插补变量，列代表为插补提供信息的变量，1和0表示使用和未使用。NonD到Gest这5行有缺失值，所以只有这5行进行了插补，每个含有缺失值的变量都利用了其他变量提供的信息来进行插补； 123# 通过提取imp对象的子成分，可以观测到实际的插补值imp$imp$Span 12345 4 3 2.0 2.0 9.0 4.5 1313 3.2 7.0 3.9 2.6 3524 12.020.220.012.0 36 3 3.0 4.5 3.0 3.0 1234# 利用complete()函数可以观察m个插补数据集中的任意一个dataset &lt;- complete(imp, action=3)head(dataset, 10) BodyWgtBrainWgtNonDDreamSleepSpanGestPredExpDanger 6654.0005712.0 3.3 0.5 3.3 38.6 645 3 5 3 1.000 6.6 6.3 2.0 8.3 4.5 42 3 1 3 3.385 44.5 10.4 2.3 12.5 14.0 60 1 1 1 0.920 5.7 14.3 2.2 16.5 2.0 25 5 2 3 2547.0004603.0 2.1 1.8 3.9 69.0 624 3 5 4 10.550 179.5 9.1 0.7 9.8 27.0 180 4 4 4 0.023 0.3 15.8 3.9 19.7 19.0 35 1 1 1 160.000 169.0 5.2 1.0 6.2 30.4 392 4 5 4 3.300 25.6 10.9 3.6 14.5 28.0 63 1 2 1 52.160 440.0 8.3 1.4 9.7 50.0 230 1 1 1 在R语言中，能够处理确实值的包有很多，这个只是比较常见的其中之一。说到底，这篇文章也只是《R语言实战》的抄写而已。我对此的理解也是表面而已。唯有在实际应用中，才能更深刻的理解和掌握缺失值的处理方法及适用范围。希望自己能常常总结分析，在这篇文章里加入更多自己的东西。]]></content>
      <categories>
        <category>R</category>
        <category>数据处理</category>
      </categories>
      <tags>
        <tag>R</tag>
        <tag>数据管理</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[R可视化之图形参数基础]]></title>
    <url>%2Fblogs%2F1f7e6963%2F</url>
    <content type="text"><![CDATA[R语言的图形参数主要由par()函数控制，图形布局主要由layout()函数控制 图形参数我们以如下数据为例 剂量(dose) 对药物A的响应(drugA) 对药物B的响应(drugB) 20 16 15 30 20 18 40 27 25 45 40 31 60 60 40 12345678910111213141516dose &lt;- c(20, 30, 40, 45, 60)drugA &lt;- c(16, 20, 27, 40, 60)drugB &lt;- c(15, 18, 25, 31, 40)# par()函数作用是全局的,使用par()修改过的参数除非会话结束，否则将一直保留，之后画# 的图形将一直使用修改过的参数绘制。opar &lt;- par(no.readonly=TRUE) # 保存原始的par参数par(lty=3,pch=8) # 设置线型线宽plot(dose,drugA,type='b') # 绘制图形par(opar) # 将参数恢复为原始参数# type='b' 表示同时绘制点和线# type='p' 表示只绘制点# type='l' 表示只绘制线# type='o' 表示绘制的线穿过点# type='c' 表示只绘制线且空出有点的地方（实际就是b模式把点去掉） 符号和线型线宽 参数 描述 默认值 lty 线条类型 solid(即1) lwd 线条宽度 1 pch 设置绘图点和符号的类型 1 cex 控制文字和绘图符号的大小，cex=1表示正常大小，0.8表示正常大小的80% 1 123456# R中的线型和线宽plot.new()plot.window(xlim = c(0, 6), ylim = c(0, 6), ann = F, asp = 1)int &lt;- 0:5+0.5abline(h = int, lty = 1:6, lwd = 1:6)text(1, int, paste(rep("lty = ", 6), 1:6, rep(", lwd = ", 6), 1:6), pos = 3) 12plot(dose,drugA,type='b',lty=3,lwd=4,pch=15,cex=3)#绘制一幅图形，其线条类型为点线，宽度为默认宽度的4倍，点的符号为实心正方形，大小为默认符号大小的3倍 颜色在R中，可以通过颜色下标、颜色名称、十六进制的颜色值、RGB值或HSV值来指定颜色。举例来说，col=1、col=”white”、col=”#FFFFFF”、col=rgb(1,1,1) 和 col=hsv(0,0,1) 都是表示白色的等价方式.colors()可以返回所有可用的颜色。当需要连续的颜色时，可以使用rainbow()函数来生成。 参数 描述 默认值 col 默认的绘图颜色。某些函数（如lines和pie）可以接受一个含有颜色值的向量并自动循环使用。例如，如果设定col=c(“red”, “blue”)并需要绘制三条线，则第一条线将为红色，第二条线为蓝色，第三条线又将为红色 ‘black’ col.axis 坐标轴刻度文字的颜色 ‘black’ col.lab 坐标轴标签（名称）的颜色 ‘black’ col.main 标题颜色 ‘black’ col.sub 副标题颜色 ‘black’ fg 图形的前景色 ‘black’ bg 图形的背景色 ‘white’ 1234mycolors &lt;- rainbow(5) # 参数为整数，表示要生成的颜色数量pie(rep(1,5), labels=mycolors, col=mycolors)mygrays &lt;- gray(0:5/5) # 生成 5阶灰度色pie(rep(1, 5), labels=mygrays, col=mygrays) 文本属性控制字号，字体， 字样 参数 描述 默认值 cex 控制文字和绘图符号的大小，cex=1表示正常大小，0.8表示正常大小的80% 1 cex.axis 坐标轴刻度位子的缩放倍数 1 cex.lab 坐标轴标签（名称）的缩放倍数 1 cex.main 主标题文字缩放倍数 1.2 cex.sub 副标题的缩放倍数 1 font 整数。用于指定绘图使用的字体样式。1=常规，2=粗体，3=斜体，4=粗斜体，5=符号字体(以Adobe符号编码表示) 1 font.axis 坐标轴刻度文字的字体样式 1 font.lab 坐标轴标签的字体 1 font.main 主标题的字体 2 font.sub 副标题的字体样式 1 ps 字体磅值（1磅约为1/72英寸）.文本的最终大小为 ps*cex 12 family 绘制文本时使用的字体族。标准的取值为serif（衬线）、sans（无衬线）和mono（等宽） ‘’ 12plot(dose,drugA,type='b',font.lab=2, cex.lab=1.5) # 坐标轴标签字体斜体且放大1.5倍text(dose-1,drugA+1,drugA,cex=0.8, font=4) # 添加文本 图形尺寸和边界尺寸 参数 描述 默认值 pin 数值型向量c(宽，高)，以英寸表示的图形尺寸 (5.4,4.8) mai 数值型向量 c(底部，左侧，上方，右侧)，设置图形边距大小，单位英寸 c(1,0.8,0.8,0.4)+0.02 mar 数值型向量 c(底部，左侧，上方，右侧)，设置图形边距大小，单位英分 c(5, 4, 4, 2) + 0.1 1234567opar &lt;- par(no.readonly=TRUE)par(pin=c(2, 3),mfcol=c(1,2))par(lwd=2, cex=1.5)par(cex.axis=.75, font.axis=3)plot(dose, drugA, type="b", pch=19, lty=2, col="red")plot(dose, drugB, type="b", pch=23, lty=6, col="blue", bg="green")par(opar) 添加文本，自定义坐标轴和图例 参数 描述 默认值 ann 控制高水平绘图函数的主标题和坐标轴标题注释，若ann=FALSE，将不显示这些注释 TRUE side 一个整数，表示在图形的哪边绘制坐标轴（1=下，2=左，3=上，4=右) at 一个数值型向量，表示需要绘制刻度线的位置 labels 一个字符型向量，表示置于刻度线旁边的文字标签（如果为NULL，则将直接使用at中的值 pos 坐标轴线绘制位置的坐标（即与另一条坐标轴相交位置的值） las 标签是否平行于（=0）或垂直于（=2）坐标轴 0 tck 刻度线的长度，以相对于绘图区域大小的分数表示（负值表示在图形外侧，正值表示在图形内侧，0表示禁用刻度，1表示绘制网格线）；默认值为-0.01） xaxt 设置x轴类型，xaxt=”n” 表示没有坐标轴，取其它值都会画出坐标轴 s yaxt 设置y轴类型，同上 s 123456plot(dose, drugA, type="b", col="red", lty=2, pch=2, lwd=2, main="Clinical Trials for Drug A", # 主标题 sub="This is hypothetical data", # 副标题 xlab="Dosage", ylab="Drug Response", # x,y轴标签 xlim=c(0, 60), ylim=c(0, 70)) # x,y轴的范围 在高级绘图函数中，都是自带坐标轴标题等属性的。如果想自定义，就要使用ann=FALSE 来禁用坐标轴注释 1234567891011121314151617x &lt;- c(1:10)y &lt;- xz &lt;- 10/xopar &lt;- par(no.readonly=TRUE)par(mar=c(5, 4, 4, 8) + 0.1) # 设置边界大小plot(x, y, type="b", pch=21, col="red", # 设置符号类型及线颜色 yaxt="n", lty=3, ann=FALSE) # 关闭坐标轴及坐标轴注释lines(x, z, type="b", pch=22, col="blue", lty=2) # 绘制 z线axis(2, at=x, labels=x, col.axis="red", las=2) # 绘制自定义x 轴axis(4, at=z, labels=round(z, digits=2), # 绘制自定义y轴 col.axis="blue", las=2, cex.axis=0.7, tck=-.01)mtext("y=1/x", side=4, line=3, cex.lab=1, las=2, col="blue") #坐标轴标签title("An Example of Creative Axes", # 标题 xlab="X values", ylab="Y=X")par(opar) 1234# 参考线abline(h=c(1,2,3), v=(4,5,6))# 在y轴1,2,3处，x轴4,5,6处添加参考线 123# 图例legend(location,title,legend....) 参数 描述 location 有许多方式可以指定图例的位置。你可以直接给定图例左上角的x、y坐标，也可以执行locator(1)，然后通过鼠标单击给出图例的位置，还可以使用关键字bottom、bottomleft、left、topleft、top、topright、right、bottomright或center放置图例。如果你使用了以上某个关键字，那么可以同时使用参数inset=指定图例向图形内侧移动的大小（以绘图区域大小的分数表示） title 图例标题的字符串（可选） legend 图例标签组成的字符型向量 … 其他选项。如果图例标示的是颜色不同的线条，需要指定col=加上颜色值组成的向量。如果图例标示的是符号不同的点，则需指定pch=加上符号的代码组成的向量。如果图例标示的是不同的线条宽度或线条类型，请使用lwd=或lty=加上宽度值或类型值组成的向量。要为图例创建颜色填充的盒形（常见于条形图、箱线图或饼图），需要使用参数fill=加上颜色值组成的向量 12345678910111213141516171819dose &lt;- c(20, 30, 40, 45, 60)drugA &lt;- c(16, 20, 27, 40, 60)drugB &lt;- c(15, 18, 25, 31, 40) # 输入数据opar &lt;- par(no.readonly=TRUE) # 保存原始参数par(lwd=2, cex=1.5, font.lab=2) # 设置线宽， 放大1.5倍， 坐标轴标签字体 粗体plot(dose, drugA, type="b", pch=15, lty=1, col="red", ylim=c(0, 60), # 设置符号类型，线型， 颜色， y轴取值范围 main="Drug A vs. Drug B", # 主标题 xlab="Drug Dosage", ylab="Drug Response")text(dose-1, drugA+1.8, drugA, col='red',cex=0.5,font=2) # 添加文本text(dose, drugB-2, drugB, col='blue',cex=0.5,font=2) # 添加文本lines(dose, drugB, type="b", pch=17, lty=2, col="blue")abline(h=c(30), lwd=1.5, lty=2, col="gray") # 参考线library(Hmisc) # 载入包minor.tick(nx=3, ny=3, tick.ratio=0.5) # 添加次要刻度线legend("topleft", inset=.05, title="Drug Type", c("A","B"), # 图例 lty=c(1, 2), pch=c(15, 17), col=c("red", "blue"))par(opar) text()可向绘图区域内部添加文本，而mtext()则向图形的四个边界之一添加文本。 参数 描述 location 文本的位置参数。可为一对x,y坐标，也可通过指定location为locator(1)使用鼠标交互式地确定摆放位置 pos 文本相对于位置参数的方位。1=下，2=左，3=上，4=右。如果指定了pos，就可以同时指定参数offset=作为偏移量，以相对于单个字符宽度的比例表示 side 指定用来放置文本的边。1=下，2=左，3=上，4=右。你可以指定参数line=来内移或外移文本，随着值的增加，文本将外移。也可使用adj=0将文本向左下对齐，或使用adj=1右上对齐 text(lacation, “text”, pos,…)mtext(“text”, side, line=n,…) 图形布局使用layout（）函数可以很容易的绘制出不同布局的拼图。layout(mat,widthhs=rep.int(1,ncol(mat)), height=rep.int(1,nrow(mat)), respect=FALSE) 参数 描述 mat 矩阵，描述绘图环境，比如matrix(c(1,2,3,3),nrow=2,ncol=2,byrow=TRUE)表示见绘图区域分割成2行2列，按列填充。第三张图占据整个第二行，前两张图平分第一行 widths 向量，分割区域宽度，widths=(2,1)表示绘图区宽度按照2:1划分 heights 向量，分割区域高度，heights=(3,1)表示绘图区高度按照3:1划分 123456789101112# 在par()函数中使用图形参数 mfrow=c(nrows, ncols)来创建按行填充的、行数为nrows、列数为ncols的图形矩阵。# nfcol=c(nrows, ncols)按列填充矩阵attach(mtcars)opar &lt;- par(no.readonly=TRUE)par(mfrow=c(2,2))plot(wt,mpg, main="Scatterplot of wt vs. mpg")plot(wt,disp, main="Scatterplot of wt vs. disp")hist(wt, main="Histogram of wt")boxplot(wt, main="Boxplot of wt")par(opar)detach(mtcars) 123456789101112# layout（）函数layout(matrix(c(1,2,3,3), nrow=2, ncol=2), widths=c(2,1)) # 设置布局 2行2列 默认列填充， 第三幅图占据3,4号位，且宽度是1,2的1/2opar &lt;- par(no.readonly=TRUE)par(mai=c(0.6,0.6,0.1,0.1),cex=0.7) # 设置图形边距及缩放0.7x &lt;- rnorm(5000) # 生成5000个标准正态分布的随机数y &lt;- rchisq(5000, 10) # 生成5000个卡方分布的随机数hist(x, prob=TRUE, col='lightblue', # x 的直方图， xlab='x', ylab='Density', # 设置坐标轴注释 ylim=c(0,0.4),main="") # 设置y轴范围，禁用主标题hist(y, freq=FALSE, col='pink', xlab="y", ylab='Density', main="")boxplot(x, col='red', lwd=1)par(opar) 1234567attach(mtcars)layout(matrix(c(1, 1, 2, 3), 2, 2, byrow = TRUE), widths=c(3, 1), heights=c(1, 2)) # 第二行高度是第一行的2倍，第三幅图的宽度是第二幅图的 1/3hist(wt)hist(mpg)hist(disp)detach(mtcars) 1234567891011121314151617# 更精细的控制图形，可以使多张图组合成一张有实际意义的图形# 利用 fig= 参数来精确的控制绘图，参数fig=的取值是一个形如c(x1, x2, y1, y2)的数值向量# 想想绘图区域是一个宽为 1 ，高为 1 的矩形，则x1, x2, y1, y2的范围就是[0,1]# fig= 默认 会新建一幅图形，所以在添加一幅图到一幅现有图形上时，请设定参数new=TRUE。opar &lt;- par(no.readonly=TRUE)par(fig=c(0, 0.8, 0, 0.8)) # 设置散点图范围plot(mtcars$mpg, mtcars$wt, # 散点图 xlab="Miles Per Gallon", ylab="Car Weight")par(fig=c(0, 0.8, 0.5, 1), new=TRUE) # 设置上方箱线图范围，宽于散点图一致，高度范围在0.5-1,。boxplot(mtcars$mpg, horizontal=TRUE, axes=FALSE) # 上方添加箱线图， 禁用坐标轴par(fig=c(0.6, 1, 0, 0.8), new=TRUE) # 设置右边箱线图，高度与散点图一直，宽度范围在0.6-1.boxplot(mtcars$wt, axes=FALSE) # 右边添加箱线图，禁用坐标轴mtext("Enhanced Scatterplot", side=3, outer=TRUE, line=-3)par(opar)]]></content>
      <categories>
        <category>R</category>
        <category>可视化</category>
      </categories>
      <tags>
        <tag>R</tag>
        <tag>可视化</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[R语言的基础语法及常用命令]]></title>
    <url>%2Fblogs%2Fdb1af4ba%2F</url>
    <content type="text"><![CDATA[R其实对于数据分析来说只是工具而已，所以刚开始不需要学习多么深多么细，只需要能够满足当前需求就行，之后的在实践中慢慢学习。毕竟想要把R学精并不是容易的事情。正确的做法就是边做边学，不会就google翻文档。本片主要是R的基础语法及常用的命令操作 赋值R赋值采用&lt;-或者-&gt;或者=，建议采用标准的第一个。由于R中内置了同名函数c()，最好不要在编码时使用c作为对象名，否则可能产生一些不易察觉的问题 1234567a &lt;- 133"hello" -&gt; b # 注意无论哪种写法，大于或小于号都是指向变量名d = 'This' # 不建议这么用，有可能会造成问题abd 133 &apos;hello&apos; &apos;This&apos; 查看帮助123help(mean)# 或者?mean 包的安装和加载1234567891011121314151617181920# 获取包含R包的库位置.libPaths()# 查看已经安装的包library()# 安装包install.packages("packagename")# 加载包library(packagesname)# 查看已经加载的包(.packages())# 卸载加载的包（注意不是删除包）detach("package:packagename")# 删除包remove.packages("packagename") 数据的读取与保存读取1234567891011121314# 读取csvdata &lt;- read.csv('.\\统计学\\example\\ch1\\table1_1.csv') head(data,6) # 读取前 6行的数据# 读取 Excel数据library(xlsx) #需要安装 xlsx 包data &lt;- read.xlsx("file",n) # n 为要导入工作表的序号# 读取 spss数据library(foregin) # 已经默认安装data &lt;- read.spss("file",use.value.labels=TRUE,as.data.frame=TRUE)# 读取 R格式数据data &lt;- load('.\\统计学\\example\\ch1\\example1_1.RData') 学生姓名统计学数学营销学管理学会计学 张青松68 85 84 89 86 王宇翔85 91 63 76 66 田思雨74 74 61 80 69 徐丽娜88 100 49 71 66 张志杰63 82 89 78 80 赵颖颖78 84 51 60 60 保存123456789# 保存 R格式数据save(data,file = '.\\...\\name.Rdata')# 保存 csv格式数据write.csv(data,file = '.\\...\\name.csv')# 保存 xlsx格式library(xlsx)write.xlsx(data, "data.xlsx",sheet.name="sheet1") if条件语句if语句1234x &lt;- 30L # R语言中，在正整数后加 L来表示整型数据（正整数）if(is.integer(x)) &#123; print("X is an Integer")&#125; [1] &quot;X is an Integer&quot; if…else语句1234567y &lt;- list('a', 'v', 'd')if('a' %in% y)&#123; # %in% 运算符 检查元素是否在向量中 print('a is in list')&#125;else&#123; # 注意这里的 else语句并不在if的花括号当中 print('a is not in list')&#125; [1] &quot;a is in list&quot; 123456789x &lt;- c("what","is","truth")if("Truth" %in% x) &#123; print("Truth is found the first time")&#125; else if ("truth" %in% x) &#123; print("truth is found the second time")&#125; else &#123; print("No truth found")&#125; [1] &quot;truth is found the second time&quot; switch语句12345678910111213# 创建一个函数，输入的值和选择的函数类型来输出结果。centre &lt;- function(x, type) &#123;switch(type, mean = mean(x), median = median(x), trimmed = mean(x, trim = .1)) &#125;centre(c(1,2,4,5),'mean') 3 循环语句while循环12345ant &lt;- 2while(ant&lt;5)&#123; print('hello') ant = ant + 1&#125; [1] &quot;hello&quot; [1] &quot;hello&quot; [1] &quot;hello&quot; for循环12345v &lt;- LETTERS[1:4] # LETTERS为26个大写字母向量。for(i in v)&#123; print(i)&#125; [1] &quot;A&quot; [1] &quot;B&quot; [1] &quot;C&quot; [1] &quot;D&quot; repeat循环12345678910i &lt;- 1sum &lt;- 0repeat&#123; sum = sum + i if( i &gt;= 100) #如果已循环加到了100，则使用break跳出repeat循环 break i &lt;- i + 1&#125;print(sum) [1] 5050 next语句R语言存在next语句，当我们想跳过循环的当前迭代而不终止它时便可使用next。 遇到next时，R解析器跳过本次迭代，并开始循环的下一次迭代。 1234567k &lt;- LETTERS[1:6]for ( i in k) &#123; if (i == "D") &#123; next &#125; print(i)&#125; [1] &quot;A&quot; [1] &quot;B&quot; [1] &quot;C&quot; [1] &quot;E&quot; [1] &quot;F&quot; R常用的常量1234567891011121314# 26个大写字母LETTERS# 26个小写字母letters# 月份简写month.abb# 月份名称month.name# π 值pi &apos;A&apos; &apos;B&apos; &apos;C&apos; &apos;D&apos; &apos;E&apos; &apos;F&apos; &apos;G&apos; &apos;H&apos; &apos;I&apos; &apos;J&apos; &apos;K&apos; &apos;L&apos; &apos;M&apos; &apos;N&apos; &apos;O&apos; &apos;P&apos; &apos;Q&apos; &apos;R&apos; &apos;S&apos; &apos;T&apos; &apos;U&apos; &apos;V&apos; &apos;W&apos; &apos;X&apos; &apos;Y&apos; &apos;Z&apos; &apos;a&apos; &apos;b&apos; &apos;c&apos; &apos;d&apos; &apos;e&apos; &apos;f&apos; &apos;g&apos; &apos;h&apos; &apos;i&apos; &apos;j&apos; &apos;k&apos; &apos;l&apos; &apos;m&apos; &apos;n&apos; &apos;o&apos; &apos;p&apos; &apos;q&apos; &apos;r&apos; &apos;s&apos; &apos;t&apos; &apos;u&apos; &apos;v&apos; &apos;w&apos; &apos;x&apos; &apos;y&apos; &apos;z&apos; &apos;Jan&apos; &apos;Feb&apos; &apos;Mar&apos; &apos;Apr&apos; &apos;May&apos; &apos;Jun&apos; &apos;Jul&apos; &apos;Aug&apos; &apos;Sep&apos; &apos;Oct&apos; &apos;Nov&apos; &apos;Dec&apos; &apos;January&apos; &apos;February&apos; &apos;March&apos; &apos;April&apos; &apos;May&apos; &apos;June&apos; &apos;July&apos; &apos;August&apos; &apos;September&apos; &apos;October&apos; &apos;November&apos; &apos;December&apos; 3.14159265358979]]></content>
      <categories>
        <category>R</category>
        <category>基础语法</category>
      </categories>
      <tags>
        <tag>R</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[R语言的数据结构]]></title>
    <url>%2Fblogs%2F8afb62cf%2F</url>
    <content type="text"><![CDATA[R共有6种储存数据的对象类型 向量 列表 数组 数据框 矩阵 因子 向量(Vectors)向量是用于存储数值型、字符型或逻辑型数据的一维数组。执行组合功能的函数c()可用来创建向量。 12345678# 创建一个向量apple &lt;- c('red','green',"yellow")num &lt;- c(12, 23, 34, 56, 78, 83)print(apple)print(num)# 查看向量的类型.print(class(apple)) [1] &quot;red&quot; &quot;green&quot; &quot;yellow&quot; [1] 12 23 34 56 78 83 [1] &quot;character&quot; !!! 单个向量中，数据的类型必须是相同的 12345678910111213# 向量元素的选取# 与其他编程语言索引从0计数不同的是，R语言的索引从1开始计数num[1]# 选取多个元素num[1:3]# 索引前加 - 号代表除去这个元素的其他元素，可以看到结果中没有第二个元素apple[-2]# 选取除了第2个和第3个元素外的其他元素num[-(2:3)] 12 12 23 34 &apos;red&apos; &apos;yellow&apos; 12 56 78 83 矩阵(Matrix)矩阵是一个二维数组，只是每个元素都拥有相同的模式（数值型、字符型或逻辑型）。可通过函数matrix创建矩阵。 123456789# matrix(data = ,nrow = n,ncol = n,byrow = ,dimnames =list(row_vector,col_vector) )# data包含了矩阵的元素# nrow和ncol用以指定行和列的维数# dimnames包含了可选的、以字符型向量表示的行名和列名# byrow则表明矩阵应当按行填充（byrow=TRUE）还是按列填充（byrow=FALSE），默认情况下按列填充。# Create a matrix.M = matrix( num, nrow = 2, ncol = 3, byrow = TRUE, dimnames = list(c('人口','面积'),c('北京','广州', '上海')))print(M) 北京 广州 上海 人口 12 23 34 面积 56 78 83 12M1 &lt;- matrix(1:20, nrow=5, ncol=4)print(M1) [,1] [,2] [,3] [,4] [1,] 1 6 11 16 [2,] 2 7 12 17 [3,] 3 8 13 18 [4,] 4 9 14 19 [5,] 5 10 15 20 12345678910111213# 矩阵元素选取# 选取列M1[,2]# 选取行M1[1,]# 选取单个元素M1[3,4]# 选取符合要求的元素M1[M1&gt;10] 6 7 8 9 10 1 6 11 16 18 11 12 13 14 15 16 17 18 19 20 数据框(data frame)数据框是表格数据对象。与矩阵一样都是二维的，但是不同的是每列可以包含不同的数据模式。 第一列可以是数字，而第二列可以是字符，第三列可以是逻辑的。它是等长度的向量的列表。 1234567df &lt;- data.frame( gender = c("Male", "Male","Female"), height = c(152, 171.5, 165), weight = c(81,93, 78), Age = c(42,38,26))df genderheightweightAge Male 152.0 81 42 Male 171.5 93 38 Female165.0 78 26 123456patientID &lt;- c(1, 2, 3, 4)age &lt;- c(25, 34, 28, 52)diabetes &lt;- c("Type1", "Type2", "Type1", "Type1")status &lt;- c("Poor", "Improved", "Excellent", "Poor")patientdata &lt;- data.frame(patientID, age, diabetes, status)patientdata patientIDagediabetesstatus 1 25 Type1 Poor 2 34 Type2 Improved 3 28 Type1 Excellent 4 52 Type1 Poor 12345# 索引列print(df$gender)print(df[,2])print(df[1:2])print(df[['Age']]) [1] Male Male Female Levels: Female Male [1] 152.0 171.5 165.0 gender height 1 Male 152.0 2 Male 171.5 3 Female 165.0 [1] 42 38 26 12# 索引行print(df[2:3,]) gender height weight Age 2 Male 171.5 93 38 3 Female 165.0 78 26 12# 特定条件索引df[df$Age &gt; 30] genderheightAge Male 152.0 42 Male 171.5 38 Female165.0 26 12345678# 索引元素print(patientdata[1,3]) # 第一列第三行print(df$Age[1]) # Age列第一行print(df[[2]][1]) # 第二列第一行print(df[['Age']][1]) # Age列第一行 [1] Type1 Levels: Type1 Type2 [1] 42 [1] 152 [1] 42 12# 生成成糖尿病类型变量diabetes和病情变量status的列联表table(patientdata$diabetes, patientdata$status) Excellent Improved Poor Type1 1 0 2 Type2 0 1 0 数组(Array)虽然矩阵被限制为二维，但数组可以具有任何数量的维度。 数组函数使用一个dim属性创建所需的维数。 在下面的例子中，我们创建了一个包含两个元素的数组，每个元素为3x3个矩阵。 123# Create an array.a &lt;- array(c('green','yellow'),dim = c(3,3,2))print(a) , , 1 [,1] [,2] [,3] [1,] &quot;green&quot; &quot;yellow&quot; &quot;green&quot; [2,] &quot;yellow&quot; &quot;green&quot; &quot;yellow&quot; [3,] &quot;green&quot; &quot;yellow&quot; &quot;green&quot; , , 2 [,1] [,2] [,3] [1,] &quot;yellow&quot; &quot;green&quot; &quot;yellow&quot; [2,] &quot;green&quot; &quot;yellow&quot; &quot;green&quot; [3,] &quot;yellow&quot; &quot;green&quot; &quot;yellow&quot; 12345dim1 &lt;- c("A1", "A2")dim2 &lt;- c("B1", "B2", "B3")dim3 &lt;- c("C1", "C2", "C3", "C4")z &lt;- array(1:24, c(2,3,4), dimnames=list(dim1, dim2, dim3))print(z) , , C1 B1 B2 B3 A1 1 3 5 A2 2 4 6 , , C2 B1 B2 B3 A1 7 9 11 A2 8 10 12 , , C3 B1 B2 B3 A1 13 15 17 A2 14 16 18 , , C4 B1 B2 B3 A1 19 21 23 A2 20 22 24 数组的索引同矩阵，只不过下标从2个变成了3个，数组同矩阵一样，数据类型必须一样 因子(Factors)我们都知道，变量的类型可以分为如下几种 类别变量（定性变量） 无序类别变量（名义值）：类别无法排序，没有顺序关系，比如行业类别，性别 有序类别变量（顺序值）：类别之间有顺序关系，比如等级，评价‘差’，‘一般’，‘很好’ 数值变量（定量变量） 离散变量（有限值）： 只能去有限个值的变量，可以一一列举。 连续变量（无限值）：在一个或多个区间内取任何值，连续不断不可一一列举，比如温度，身高。 类别变量在R中被称为因子，函数factor()以一个整数向量的形式存储类别值，整数的取值范围是[1-k ]（其中k 是名义型变量中唯一值的个数），同时一个由字符串（原始值）组成的内部向量将映射到这些整数上。这种做法类似于python特征分子中的将类别变量dummy化 对于有序变量，我们还可以指定变量对应的编码，使编码与逻辑顺序相一致，比如low,mid,high对应1,2,3 12345678910patientID &lt;- c(1, 2, 3, 4)age &lt;- c(25, 34, 28, 52)diabetes &lt;- c("Type1", "Type2", "Type1", "Type1")status &lt;- c("Poor", "Improved", "Excellent", "Poor")diabetes &lt;- factor(diabetes)status &lt;- factor(status, order=TRUE) # order=TRUE R将此变量当做有序变量对待patientdata &lt;- data.frame(patientID, age, diabetes, status)str(patientdata） # 数据的信息，相当于pandas中的infosummary(patientdata) # 描述性统计# 可以看到，描述性统计中，R对数值型分析了最大最小值等，而对因子采用了频数统计。 &apos;data.frame&apos;: 4 obs. of 4 variables: $ patientID: num 1 2 3 4 $ age : num 25 34 28 52 $ diabetes : Factor w/ 2 levels &quot;Type1&quot;,&quot;Type2&quot;: 1 2 1 1 $ status : Ord.factor w/ 3 levels &quot;Excellent&quot;&lt;&quot;Improved&quot;&lt;..: 3 2 1 3 patientID age diabetes status Min. :1.00 Min. :25.00 Type1:3 Excellent:1 1st Qu.:1.75 1st Qu.:27.25 Type2:1 Improved :1 Median :2.50 Median :31.00 Poor :2 Mean :2.50 Mean :34.75 3rd Qu.:3.25 3rd Qu.:38.50 Max. :4.00 Max. :52.00 12345# 如果变量的默认顺序不是按照逻辑顺序排列的，比如status如果是按照improved,poor,excellent排列，# 那么默认的顺序就无法代表真实逻辑顺序。# 因此，可以添加levels变量status &lt;- factor(status,order=TRUE,levels = c("poor", "improved", "excellent"))# 这样就相当于指定了顺序，任何在数据中出现而未在参数中列举的数据都将被设为缺失值 列表R中的列表比较像python中的列表，列表中的元素可以是单个字符，数值，也可以是向量，矩阵，数组等列表就是一些对象的有序集合 12345# Create a list.list1 &lt;- list(c(2,5,3),21.3,sin)# Print the list.print(list1) [[1]] [1] 2 5 3 [[2]] [1] 21.3 [[3]] function (x) .Primitive(&quot;sin&quot;) 123456g &lt;- "My First List"h &lt;- c(25, 26, 18, 39)j &lt;- matrix(1:10, nrow=5)k &lt;- c("one", "two", "three")mylist &lt;- list(title=g, ages=h, j, k)print(mylistlist) $title [1] &quot;My First List&quot; $ages [1] 25 26 18 39 [[3]] [,1] [,2] [1,] 1 6 [2,] 2 7 [3,] 3 8 [4,] 4 9 [5,] 5 10 [[4]] [1] &quot;one&quot; &quot;two&quot; &quot;three&quot; 12mylist[['ages']] # 输出agesmylist[[2]] # 输出第二个元素 25 26 18 39 25 26 18 39 处理数据的常用函数1234567891011121314151617181920212223242526272829303132333435363738394041424344454647length(object) # 显示对象中元素/成分的数量dim(object) # 显示某个对象的维度str(object) # 显示某个对象的结构class(object) # 显示某个对象的类或类型mode(object) # 显示某个对象的模式names(object) # 显示某对象中各成分的名称c(object, object,…) # 将对象合并入一个向量cbind(object, object, …) # 按列合并对象rbind(object, object, …) # 按行合并对象Object # 输出某个对象head(object) # 列出某个对象的开始部分tail(object) # 列出某个对象的最后部分ls() # 显示当前的对象列表rm(object, object, …) # 删除一个或更多个对象。语句rm(list = ls())将删除当前工作环境中的几乎所有对象,以句点.开头的隐藏对象将不受影响newobject &lt;- edit(object) # 编辑对象并另存为newobjectfix(object) # 直接编辑对象]]></content>
      <categories>
        <category>R</category>
        <category>基础语法</category>
      </categories>
      <tags>
        <tag>R</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[在jupyter notebook中使用R]]></title>
    <url>%2Fblogs%2F2f83e5a7%2F</url>
    <content type="text"><![CDATA[本来我是不打算学习R语言的，毕竟学习了python，已经能够满足大部分需求了。但是最近报了人大的统计学在职研究生，老师说以后的论文是必须要用R语言来写的。(￣▽￣)~* 那就学吧。因为之前一直在用jupyter notebook来写分析报告，所以我就想也用jupyter写R，这样子就很方便了。高兴的是确实可以在jupyter中使用R，但是在网上很难找到教程，好在翻了官网说明后终于搞定了，在这里记录下方法。供日后查阅。(*^▽^*) R的安装R的安装网上教程很多，我就不多赘述了，挺简单的。直接去官网下载文件一路火花带闪电的下一步就可以了。下载地址：R官网下载地址 Rstudio的安装毕竟jupyter多用在展示报告上面，并不适合写工程化的程序。而R的IDE还是推荐Rstudio的，有免费版，可以满足大部分需求。下载地址：Rstudio下载地址 关联jupyter notebook如果你没有安装jupyter notebook，需要先安装。我推荐直接使用anaconda，上面自带jupyter notebook而且环境配置都帮你搞定了，自带python相当于最后R和python都可以用。首先我们打开R的命令行，如果不知道可以直接打开Rsudio，在左下角的console里写如下命令： 12install.packages(c('repr', 'IRdisplay', 'evaluate', 'crayon', 'pbdZMQ', 'devtools', 'uuid', 'digest'))devtools::install_github('IRkernel/IRkernel') 上面的代码会自动分两步执行，执行完后，在输入如下代码中的一个： 12345# 只在当前用户下安装IRkernel::installspec()# 或者是在系统下安装IRkernel::installspec(user = FALSE) 等待执行完毕，打开jupyter就可以新建R的notebook了。恩~ 就是这么简单，接下来就可以愉快的写R了]]></content>
      <categories>
        <category>R</category>
      </categories>
      <tags>
        <tag>R</tag>
        <tag>jupyter notebook</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ACG音乐推荐(1) —— 那些最喜欢的]]></title>
    <url>%2Fblogs%2Fc784bcde%2F</url>
    <content type="text"><![CDATA[想想算来入宅3有余，看了也有200多部动漫了 ，喜欢的动画音乐也不计其数。动画音乐自出生起就有动画本身所赋予的情感生命。所以，对于我来说每一首动画音乐都是有生命的，都是来自某个动画世界里的声音。 但是，人的精力总归是有限的，不可每天都能把所有的听一遍，所以这里就要发挥人类喜欢排名这个喜好了。在这里推荐一些我最喜欢的ACG音乐。 我一直相信好的音乐是能够与心共鸣的。 さようなら（再见）——《小林家的龙女仆》 人和龙这样差别如此巨大的生物能否生活在一起呢？或者说观念和经历迥然不同的两个人能否做朋友甚至家人呢？ “人类有能相处的和不能相处的”“不能相处的人类一眼就能看出”“能相处的人类却要花时间才能了解”“为了区区人类花费这些时间太麻烦了”“对我而言”“人类只是随意踏入别人居所”“欲图夺走宝藏的生物就足够了”“但是……” 只要相互尊重，相互了解，便能彼此靠近。毕竟即使是高高在上的龙，也有一颗孤独，渴望被理解的心呐。 人总是把习以为常当做理所应当，在失去的时候才知道有多么宝贵。 “早知道会这样，真应该多夸夸她做的蛋包饭……” 对于托尔来说，小林的一生只相当于龙的几个月而已,转眼就是生死离别。 “可是，我最喜欢小林了” 若是惧怕彼此伤害而选择不靠近，那么一切都没有了意义。正是因为有了幸福的记忆，分别才会伤感。既然分别不可避免，何不珍惜如今的每一刻。每当听到这首音乐，不论开心，还是不开心，无论生活如何欺骗我，让我有着怎么样的心情，都能让我瞬间平静，去接纳我所经历的每一刻。去期待未来的每一种可能。 きみにとどけ(留在你身边） —— 《好想告诉你》 这份天真烂漫的心情也好那一同开怀大笑的日子也好我都想慎重地培养好它们你穿过断断续续的时空给了我许多的第一次连接起来 到达你身边 这首歌是少有的我没看完动画但依然百听不厌的。（剧情真的快急死我了，真不愧“好想急死你”）老夫的少女心啊~~~我想谈恋爱~每次听这首歌心情都能好起来，可能是因为这首歌将那份青涩的爱情完美的传达了吧。 ヒャダインとももクロのじょーじょーゆーじょー —— 《日常》OP2 我们每天度过的所谓的日常，说不定是一个个连续的奇迹呢 最上川 i do —— 《攻壳机动队》 其实在入宅之前就听过攻壳的大名，但知道入宅很久后，也一直没有看。直到听到这首歌（话说我的很多补番都是因为先听歌然后才去看的动画）。才开始慢慢补动画。不过到现在也没看完，或许等到补完。对于这首歌能有更多的感触。 again —— 《钢之炼金术师》ブラーチヤ ——《钢之炼金术师》 钢炼无疑是一部极为优秀的动画，但相较于动画，我更喜欢这两首音乐。特别是第二首兄弟 亲爱的妈妈！你是如此温柔！我們很爱你。但我們所有的努力竟都是徒劳无功的。我自己被美丽的希望所诱惑想要回到我們的家我的兄弟，都是我的错。但我们应该怎么办？ 可以说是完美的表现了那场禁忌术式之后兄弟二人复活母亲愿望破灭后的痛苦，哥哥另弟弟失去身体的自责和懊悔，和兄弟二人擦干眼泪决心向前的心情。 となりのトトロ —— 《龙猫》 永远不会忘记两个小女孩围着一夜长出来的小树高兴的一遍一遍喊道： “好像在做梦”“可是不是梦” 也永远不会忘记猫巴士在田野上奔驰的身影。人们说，长大了，就在也看不到龙猫了。是么？另外，伊藤サチコ老师的吉卜力翻唱集里翻唱了很多宫崎骏动画的歌曲，也很不错。推荐。 今まで何度も —— 《火影忍者》 作为从小学追火影十几年到大学的人，实在不知道那首歌是最喜欢的。记得小时候除了电视里放的龙珠，数码宝贝这些，火影只能从哥哥给我的盗版光盘里看到。所以前100多集不知道在DVD里看了多少遍，里面的音乐都成为了童年珍贵的记忆，况且确实很棒。不过非要我选一首的话，我选择这首今まで何度も，即使现在我还常听。 今まで何度も なんとかあきらめずに迄今为止 有数次 总之别放弃今まで何度も 立ちあがってきたじゃないか迄今为止 有数次 为何不能重新振作今まで何度も 僕ら 何度も 信じて 何度も 夢見て迄今为止 有数次 重新相信 有数次 梦见何度も…有数次…今まで何度も バカを見てきたじゃないか迄今为止 有数次 都是懊恼万分今まで何度も 人のかげに立ってきたじゃないか迄今为止 有数次 在逆境中成长さぁ 主役だよ 自分の夢くらい わがままでいさせて 这就是坚强的意志 放任自己去追求心中的梦想吧 这首歌就是那时我对火影里人物的印象，一群无论有什么困难，无论失败多少次都能再次站起来追求梦想的人。没有转世什么的……还有，那时的火影拯救了我。 One more time, One more chance —— 《秒速五厘米》 呐，你知道吗？听说樱花飘落的速度是秒速五厘米哦 这首我觉得就不需要多说了。 For フルーツバスケット —— 《水果篮子》 记得是小时候应该星空卫视播放过，虽然我一点都不记得动画讲的什么，后来遇到这首歌，如此柔软的声音，我想动画里也一定有如此温柔的人吧。直到现在我都没看这部动画，没有各种原因，只是觉得这首歌就够了，听了这首歌仿佛就能感受到动画里传达的感情。 たとえ苦しい今日だとしても即使今天充满痛苦いつかあたたかな想い出になる总有一天 它会成为温馨的回忆心ごとすべてなげだせたなら只要我们的心被感动ここに生きてる意味がわかるよ我明白生存在这的意义生まれおちた歓びを知る也了解诞生于世的快乐Let’s stay together いつも让我们永远在一起 如此美丽的声音，却因癌症在04年离而消逝。 secret base ~君がくれたもの~ (10 years after Ver.) —— 《未闻花名》 虽然这首歌不是动画原创，但是我觉得还是写上来吧。 最喜欢仁太了，是想成为仁太新娘的那种喜欢面码，找到你了 催人泪下的剧情，加上这音乐，每到关键时刻这首歌就会响起，于是搞得眼泪在不停的在眼里打转。第一次感受到了音乐出现时机的重要性。 あなたがいた森 (曾有你的森林)——《Fate/Stay night 》 每次听到这首歌就想到吾王站在草原上杵着剑，微风吹过金发的样子，好美。 遵从召唤而来，我问你，你是我的Master吗?贝狄威尔，不要露出这样的表情. 剑鞘正在治疗我的伤， 我不会就这样一睡不醒的.抱歉贝狄威尔 这次我将会…睡得…久一点… God knows —— 《凉宫春日的忧郁》 いつもの風景 —— 《凉宫春日的忧郁》 第一首相信不用多提，即使没看过凉宫，那个文化祭的演唱片段也一定会看过。最令我印象深刻的就是大明神的吉他了，我不懂音乐，但我就是觉得好听，厉害。从此越来越多的动画开起了演唱会，但令我无法忘记的只有这一个。第二首如果看过凉宫一定不会陌生，它常常伴随着阿虚的吐槽出现。每当听到这首歌，都会想起阿虚那关于外星人的开场吐槽。心情大好。 いのちの名前 —— 《千与千寻》 不要吃得太胖哦 会被杀掉的没记错的话这首歌在动画里只是插曲，且没有人声的。但是比起纯音乐的版本，我更喜欢这个有歌词的版本。没到那个听到这首歌总能想起千寻倔强的要婆婆给她一份工作想起千寻为河神洗澡时跌入淤泥里的样子想起千寻对父母大喊不要吃太胖哦，会被杀掉的想起千寻与无脸男在坐在海面上的火车缓缓前行和在车站上永远在等待的小女孩不要忘记自己的名字，你就能找到回去的路 音乐这东西，好听不好听全凭个人喜好，讨厌可以有很多理由，但是喜欢就是喜欢，不需要什么理由只要这个音乐能打动你，能与你的心共鸣，就是好音乐。我喜欢的音乐还有很多，我只是把我百听不厌的一部分写了出来。剩下没写的和未来喜欢的，就在未来某时某刻我再来补充吧。]]></content>
      <categories>
        <category>Music</category>
      </categories>
      <tags>
        <tag>Music</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[kaggle：泰坦尼克幸存者预测]]></title>
    <url>%2Fblogs%2Ff4fe8c7c%2F</url>
    <content type="text"><![CDATA[泰坦尼克号是当时（1912年）世界上体积最庞大、内部设施最豪华的客运轮船，有“永不沉没”的美誉 。然而在首次航行中，泰坦尼克号与一座冰山相撞，逾1500人丧生，其中仅333具罹难者遗体被寻回。泰坦尼克号沉没事故为和平时期死伤人数最惨重的海难之一，其残骸直至1985年才被再度发现，目前受到联合国教育、科学及文化组织的保护。本次竞赛以此为背景，根据提供的乘客数据来预测这些乘客能否生还（当然真实的情况要比这复杂得多）。 123456789101112import pandas as pdimport numpy as npimport matplotlib.pyplot as pltimport seaborn as snsimport osimport warningswarnings.filterwarnings('ignore')%matplotlib inlineimport matplotlibmatplotlib.rcParams['axes.unicode_minus']=False 导入数据12345titanic = pd.read_csv(r'E:\DataScience\ML\Titanic\train.csv')titanic_test = pd.read_csv(r'E:\DataScience\ML\Titanic\test.csv')titanic.head(10) .dataframe tbody tr th:only-of-type {vertical-align: middle;}.dataframe tbody tr th {vertical-align: top;}.dataframe thead th {text-align: right;}PassengerIdSurvivedPclassNameSexAgeSibSpParchTicketFareCabinEmbarked0103Braund, Mr. Owen Harrismale22.010A/5 211717.2500NaNS1211Cumings, Mrs. John Bradley (Florence Briggs Th…female38.010PC 1759971.2833C85C2313Heikkinen, Miss. Lainafemale26.000STON/O2. 31012827.9250NaNS3411Futrelle, Mrs. Jacques Heath (Lily May Peel)female35.01011380353.1000C123S4503Allen, Mr. William Henrymale35.0003734508.0500NaNS5603Moran, Mr. JamesmaleNaN003308778.4583NaNQ6701McCarthy, Mr. Timothy Jmale54.0001746351.8625E46S7803Palsson, Master. Gosta Leonardmale2.03134990921.0750NaNS8913Johnson, Mrs. Oscar W (Elisabeth Vilhelmina Berg)female27.00234774211.1333NaNS91012Nasser, Mrs. Nicholas (Adele Achem)female14.01023773630.0708NaNC 单词 翻译 Key survival 是否幸存 0 = No, 1 = Yes pclass 社会阶层 1 = 精英, 2 = 中层 , 3 = 普通民众 sex 性别 Age 年龄 sibsp 船上兄弟/姐妹的个数 parch 船上父母/孩子的个数 ticket 船票号 fare 船票价格 cabin 船舱号码 embarked 登船口 C = Cherbourg, Q = Queenstown, S = Southampton 123# 查看数据简单的统计titanic.describe() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } PassengerId Survived Pclass Age SibSp Parch Fare count 891.000000 891.000000 891.000000 714.000000 891.000000 891.000000 891.000000 mean 446.000000 0.383838 2.308642 29.699118 0.523008 0.381594 32.204208 std 257.353842 0.486592 0.836071 14.526497 1.102743 0.806057 49.693429 min 1.000000 0.000000 1.000000 0.420000 0.000000 0.000000 0.000000 25% 223.500000 0.000000 2.000000 20.125000 0.000000 0.000000 7.910400 50% 446.000000 0.000000 3.000000 28.000000 0.000000 0.000000 14.454200 75% 668.500000 1.000000 3.000000 38.000000 1.000000 0.000000 31.000000 max 891.000000 1.000000 3.000000 80.000000 8.000000 6.000000 512.329200 123# 查看数据概要titanic.info() &lt;class &apos;pandas.core.frame.DataFrame&apos;&gt; RangeIndex: 891 entries, 0 to 890 Data columns (total 12 columns): PassengerId 891 non-null int64 Survived 891 non-null int64 Pclass 891 non-null int64 Name 891 non-null object Sex 891 non-null object Age 714 non-null float64 SibSp 891 non-null int64 Parch 891 non-null int64 Ticket 891 non-null object Fare 891 non-null float64 Cabin 204 non-null object Embarked 889 non-null object dtypes: float64(2), int64(5), object(5) memory usage: 83.6+ KB 从上可以看出，Age,Cabin,Fare,Embarked几个特征存在空值 123# 统计空值print(titanic.isnull().sum()) PassengerId 0 Survived 0 Pclass 0 Name 0 Sex 0 Age 177 SibSp 0 Parch 0 Ticket 0 Fare 0 Cabin 687 Embarked 2 dtype: int64 数据清洗处理缺失值12345678910# 可以填充整个dataframe的空值# titanic.fillna(0)# 也可以单独填充一列# titanic.Age.fillna(0)titanic.Age.fillna(-30, inplace=True)#查看为空的数据titanic.isnull().sum() PassengerId 0 Survived 0 Pclass 0 Name 0 Sex 0 Age 0 SibSp 0 Parch 0 Ticket 0 Fare 0 Cabin 687 Embarked 2 dtype: int64 数据分析性别Sex对生还与否的影响12# 做简单是汇总统计titanic.groupby(['Sex','Survived'])['Survived'].count() Sex Survived female 0 81 1 233 male 0 468 1 109 Name: Survived, dtype: int64 1234# 生还率统计df_sex = titanic[['Sex','Survived']].groupby(['Sex']).mean()df_sex .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } Survived Sex female 0.742038 male 0.188908 12345678# 绘制柱状图df_sex.plot(kind='bar', figsize=(8,6), rot=0, fontsize=18, stacked=True)plt.grid(True, linestyle='--') 从上面可以发现，事实是与男性比女性的生存能力更强的经验常识相悖的，可以推测Lady First起到了很大的作用 社会阶层 Pclass与生还与否的关系12# 统计titanic.groupby(['Pclass', 'Survived'])['Pclass'].count() Pclass Survived 1 0 80 1 136 2 0 97 1 87 3 0 372 1 119 Name: Pclass, dtype: int64 12df_pclass = titanic[['Pclass', 'Survived']].groupby(['Pclass']).mean()df_pclass .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } Survived Pclass 1 0.629630 2 0.472826 3 0.242363 1234567# 绘制柱状图df_pclass.plot(kind='bar', rot=0, fontsize=18, figsize=(8,6))plt.show() 可以看到，等级越高的人，生存几率越大，那么ladyfirst能否跨越等级界限呢？ 12df_psex = titanic[['Pclass', 'Sex', 'Survived']].groupby(['Pclass', 'Sex']).mean()df_psex .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } Survived Pclass Sex 1 female 0.968085 male 0.368852 2 female 0.921053 male 0.157407 3 female 0.500000 male 0.135447 12345df_psex.plot(kind='bar', rot=0, fontsize=12, figsize=(8,6))plt.show() 可以看到，ladyfirst确实跨越了社会等级界限，普通阶层的女性的生还率都高于精英阶层的男性生还率。不过，无法忽视的是，不同等级的生还率还是有一定区别的。 年龄Age对生还与否的影响绘图分析不同阶层和不同性别下的年龄分布情况以及与生还的关系 1234567891011# 绘图分析不同阶层和不同性别下的年龄分布情况以及与生还的关系fig, ax = plt.subplots(1, 2, figsize=(18,8))sns.violinplot('Pclass','Age', hue='Survived', data=titanic, split=True, ax=ax[0])ax[0].set_title('Pclass and Age vs Survived',size=18)ax[0].set_yticks(range(0, 110, 10))sns.violinplot("Sex", "Age", hue="Survived", data=titanic, split=True, ax=ax[1])ax[1].set_title('Sex and Age vs Survived',size=18)ax[1].set_yticks(range(0, 110, 10))plt.show() 12345678910# 统计总体的年龄分布plt.figure(figsize=(10,6))plt.subplot(1,2,1)titanic['Age'].hist(bins=20)plt.xlabel('Age')plt.ylabel('Num')plt.subplot(1,2,2)titanic.boxplot(column='Age', showfliers=False)plt.show() 因为年龄缺失值填充的问题，所以中间高出很多 12345page = sns.FacetGrid(titanic, hue="Survived",aspect=4)page.map(sns.kdeplot,'Age',shade= True)page.set(xlim=(-40, titanic['Age'].max()))page.add_legend()plt.show() 可以看到，孩子和中年人更容易获救。那么规则就是 lady and children first，缺省值中死亡更多所以无法统计到年龄 123456f, ax = plt.subplots(figsize=(8,3))ax.set_title('Sex Age dist', size=20)sns.distplot(titanic[titanic.Sex=='female'].dropna().Age, hist=False, color='pink', label='female')sns.distplot(titanic[titanic.Sex=='male'].dropna().Age, hist=False, color='blue', label='male')ax.legend(fontsize=15)plt.show() 可以看到，女性更加年轻些，孩子和中老年人中男性更多 1234567f, ax = plt.subplots(figsize=(8,3))ax.set_title('Pclass Age dist', size=20)sns.distplot(titanic[titanic.Pclass==1].dropna().Age, hist=False, color='pink', label='P1',rug=True)sns.distplot(titanic[titanic.Pclass==2].dropna().Age, hist=False, color='blue', label='p2',rug=True)sns.distplot(titanic[titanic.Pclass==3].dropna().Age, hist=False, color='g', label='p3',rug=True)ax.legend(fontsize=15)plt.show() 阶层越高，年纪更老龄化 有无兄弟姐妹 SibSp 对生还与否的影响1234# 首先将数据分为有兄弟姐妹和没有兄弟姐妹两组df_sibsp = titanic[titanic['SibSp'] != 0]df_sibsp_no = titanic[titanic['SibSp'] == 0] 12345678910plt.figure(figsize=(12,6))plt.subplot(1,2,1)df_sibsp['Survived'].value_counts().plot(kind='pie',labels=['No Survived', 'Survived'], autopct = '%1.1f%%')plt.xlabel('sibsp',fontsize=18)plt.subplot(1,2,2)df_sibsp_no['Survived'].value_counts().plot(kind='pie',labels=['No Survived', 'Survived'], autopct = '%1.1f%%')plt.xlabel('sibsp_no',fontsize=18)plt.show() 有了兄弟姐妹的帮助，似乎更能在险境中存活 有无父母孩子 Parch 对生还与否的影响方法同上 1234567891011121314# 按照有无父母孩子分组df_parch = titanic[titanic['Parch'] != 0]df_parch_no = titanic[titanic['Parch'] == 0]plt.figure(figsize=(12,6))plt.subplot(1,2,1)df_sibsp['Survived'].value_counts().plot(kind='pie',labels=['No Survived', 'Survived'], autopct = '%1.1f%%')plt.xlabel('Parch',fontsize=18)plt.subplot(1,2,2)df_sibsp_no['Survived'].value_counts().plot(kind='pie',labels=['No Survived', 'Survived'], autopct = '%1.1f%%')plt.xlabel('Parch_no',fontsize=18)plt.show() 从之前的分析中知道，孩子是特殊照顾的对象，而孩子一般是有父母跟随的。即使都是成年人，互相帮助存活概率也更高。 亲人数量对生还与否的影响是否亲人越多，生还可能性越大呢？ 1234567fig,ax = plt.subplots(1, 2, figsize=(12,8))titanic[['Parch','Survived']].groupby(['Parch']).mean().plot(kind='bar',ax=ax[0])ax[0].set_title('Parch and Survived')titanic[['SibSp','Survived']].groupby(['SibSp']).mean().plot.bar(ax=ax[1])ax[1].set_title('SibSp and Survived')plt.show() 123titanic['fam_size'] = titanic['SibSp'] + titanic['Parch'] + 1titanic[['fam_size','Survived']].groupby(['fam_size']).mean().plot.bar(figsize=(8,6))plt.show() 从上可以看出，家庭成员在1-4人生还率最高，推测应该是这样正好组成了可以互帮互助，行动又不臃肿从小组。而后面7人家庭成员的存活率上升，推测应该是人数上升后，至少存活一人的概率增加。 票价 Fare 对生还与否的影响12345# 绘制票价分布图titanic['Fare'].plot(kind='hist',bins=100,figsize=(10,6), grid=True)titanic.boxplot(column='Fare', by='Pclass',showfliers=False,figsize=(10,6))plt.show() 1titanic['Fare'].describe() count 891.000000 mean 32.204208 std 49.693429 min 0.000000 25% 7.910400 50% 14.454200 75% 31.000000 max 512.329200 Name: Fare, dtype: float64 12# 绘制生还者非生还者票价分析titanic.boxplot(column='Fare', by='Survived',showfliers=False,showmeans=True) 可以看到，幸存者的票价普遍更高，符合之前阶层越高，生还几率越大的推测 船舱号码 Cabin 对生还与否的影响按照查询的资料，我认为乘客所处的船舱应该是跟是否生还有很大关系的，特别是下层的乘客，下部船舱快速进水，通向甲板的路不难想象也是混作一团，这就大大减少了生还可能。但是，此字段缺失数据多达600多个，所以只做下简单的数据分析。（不过我认为，票价和船舱应该有对应关系，如果能知道票价与船舱对应的史料就最好了） 1titanic.Cabin.isnull().value_counts() True 687 False 204 Name: Cabin, dtype: int64 1titanic.groupby(by=titanic.Cabin.isnull())['Survived'].mean() Cabin False 0.666667 True 0.299854 Name: Survived, dtype: float64 由上可知，缺失值的生存率很低，那么可以将Cabin是否为空作为一个特征！ 123456789titanic['Cabin_fir'] = titanic.Cabin.fillna('0').str.split(' ').apply(lambda x: x[0][0])df_cabin_fir = titanic.groupby(by='Cabin_fir')['Survived'].mean()print(df_cabin_fir)df_cabin_fir.plot(kind='bar', rot=0, legend=True,figsize=(10,8), fontsize=12)plt.show() Cabin_fir 0 0.299854 A 0.466667 B 0.744681 C 0.593220 D 0.757576 E 0.750000 F 0.615385 G 0.500000 T 0.000000 Name: Survived, dtype: float64 12df_cabin_fare = titanic.groupby(by='Cabin_fir')['Fare','Survived'].mean()df_cabin_fare .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } Fare Survived Cabin_fir 0 19.157325 0.299854 A 39.623887 0.466667 B 113.505764 0.744681 C 100.151341 0.593220 D 57.244576 0.757576 E 46.026694 0.750000 F 18.696792 0.615385 G 13.581250 0.500000 T 35.500000 0.000000 在有记录的乘客中，可以发现，BC舱位总统套间，掏钱最多，DE为贵宾舱，费用中等，其余为普通舱。生还率大致符合阶层的情况。至于为何C舱生还率低于BDE，暂不分析，推测应该与所处舱位位置不佳，男性占比大，年龄偏大有关。 登船地点 Embarked 对生还与否的影响 泰坦尼克号从英国南安普敦出发，途经法国瑟堡-奥克特维尔以及爱尔兰昆士敦 —— 百度百科 南安普顿对应 S = Southampton， 瑟堡-奥克特维尔对应 C = Cherbourg，昆士敦对应 Q = Queenstown 12titanic.groupby(by='Embarked')['Survived'].mean().plot(kind='bar', rot=0, fontsize=15, legend=True)plt.show() 12df_embarked = titanic.groupby(by='Embarked')['Survived','Fare'].agg(['mean', 'count'])df_embarked .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead tr th { text-align: left; } .dataframe thead tr:last-of-type th { text-align: right; } Survived Fare mean count mean count Embarked C 0.553571 168 59.954144 168 Q 0.389610 77 13.276030 77 S 0.336957 644 27.079812 644 1234567ax = plt.figure(figsize=(10,6)).add_subplot(111)ax.set_xlim([-40, 80])sns.kdeplot(titanic[titanic.Embarked=='C'].Age, ax=ax, label='C')sns.kdeplot(titanic[titanic.Embarked=='Q'].Age, ax=ax, label='Q')sns.kdeplot(titanic[titanic.Embarked=='S'].Age, ax=ax, label='S')ax.legend(fontsize=18)plt.show() C和S上岸的乘客的年龄分布较为相似，Q上岸的人很多没有年龄。C和S比较，C口岸的人中有更多的孩子和老人 名字 Name 对生还与否的影响\通过对名字该字段的初步观察，发现名字中不但透漏出性别，还代表着一个人的地位，年龄，职业等比如Master，Miss等 123# 称谓统计titanic['Title'] = titanic.Name.apply(lambda x: x.split(',')[1].split('.')[0])titanic['Title'].value_counts() Mr 517 Miss 182 Mrs 125 Master 40 Dr 7 Rev 6 Mlle 2 Major 2 Col 2 the Countess 1 Don 1 Jonkheer 1 Mme 1 Capt 1 Sir 1 Lady 1 Ms 1 Name: Title, dtype: int64 12# 姓氏统计titanic.Name.apply(lambda x: x.split(',')[1].split('.')[1]).value_counts()[:10] John 9 James 7 Mary 6 William 6 William Henry 4 Bertha 4 Ivan 4 William John 4 Samuel 3 Patrick 3 Name: Name, dtype: int64 1titanic[['Title','Survived']].groupby(['Title']).mean() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } Survived Title Capt 0.000000 Col 0.500000 Don 0.000000 Dr 0.428571 Jonkheer 0.000000 Lady 1.000000 Major 0.500000 Master 0.575000 Miss 0.697802 Mlle 1.000000 Mme 1.000000 Mr 0.156673 Mrs 0.792000 Ms 1.000000 Rev 0.000000 Sir 1.000000 the Countess 1.000000 123# 不同称呼的生存率统计titanic[['Title','Survived']].groupby(['Title']).mean().plot.bar(rot=45, figsize=(15,6), fontsize=12)plt.show() 可以看到，称谓确实与获救率有关，以为称谓往往与人的性别，地位有关。 换个角度，我们知道，歪果仁的名字中通常会加入家族名字，爵位等，所以是不是名字越长就越能像是一个家族的历史和地位呢？那么名字的长短是否能够显示出人的地位从而影响到是否获救？ 1234titanic['name_len'] = titanic['Name'].apply(len)df_namelen = titanic[['name_len','Survived']].groupby(['name_len'],as_index=False).mean()df_namelen.plot.bar(x='name_len',y='Survived',figsize=(18,6),rot=0,colormap='Blues_r',alpha=0.6,fontsize=12)plt.show() 看来猜想是正确的，名字的长度确实与是否获救有一定关系 Ticket类别比较大，观察可以发现，票号开头应该代表着船舱区域，故提取分析 123titanic['Ticket_Lett'] = titanic['Ticket'].apply(lambda x: str(x)[0])titanic['Ticket_Lett'] = titanic['Ticket_Lett'].apply(lambda x: str(x))titanic.groupby(titanic['Ticket_Lett'])['Survived'].mean() Ticket_Lett 1 0.630137 2 0.464481 3 0.239203 4 0.200000 5 0.000000 6 0.166667 7 0.111111 8 0.000000 9 1.000000 A 0.068966 C 0.340426 F 0.571429 L 0.250000 P 0.646154 S 0.323077 W 0.153846 Name: Survived, dtype: float64 1titanic.groupby(titanic['Ticket_Lett'])['Survived'].mean().plot.bar(rot=0) 可以看到，船票不同开头的生存率不同，可以作为一个特征 通过以上的分析，我们发现，乘客获救与否，与多种因素有关。包括性别，年龄，阶级等。在这大灾难面前，强壮的男人死亡率反常的高，而女人和孩子反而更易存活，这不正常，但也是正常的，这应该就是文明发展的结果。 那么，如果你当时在泰坦尼克上，你是否会成功获救呢？下篇文章，将通过机器学习算法，来预测另一批乘客是否会活下来。 特征工程变量转换 变量转换的目的是将数据转换为适用于模型使用的数据，不同模型接受不同类型的数据，Scikit-learn要求数据都是数字型numeric，所以我们要将一些非数字型的原始数据转换为数字型numeric 12345678910from sklearn.preprocessing import LabelEncoderfrom sklearn.model_selection import train_test_splitfrom sklearn.linear_model import LogisticRegressionfrom sklearn.svm import SVCfrom sklearn.ensemble import RandomForestClassifierfrom sklearn.neighbors import KNeighborsClassifierfrom sklearn.tree import DecisionTreeClassifierfrom xgboost import XGBClassifierimport warningswarnings.filterwarnings('ignore') 1234os.chdir('E:\DataScience\ML\Titanic')data_train = pd.read_csv('train.csv')data_test = pd.read_csv('test.csv')combine = pd.concat([data_train,data_test]) 对数据进行特征工程，也就是从各项参数中提取出对输出结果有或大或小的影响的特征，将这些特征作为训练模型的依据。 一般来说，我们会先从含有缺失值的特征开始 Embarked因为该项的缺失值没几个，所以这里我们以众数来填充： 123456# 缺失值填充，众数为 Scombine['Embarked'] = combine['Embarked'].fillna('S')# dummy处理df = pd.get_dummies(combine['Embarked'], prefix='Embarked')combine = pd.concat([combine, df], axis=1).drop('Embarked', axis=1) Name_length1combine['Name_length'] = combine['Name'].apply(len) Title123456789combine['Title'] = combine['Name'].apply(lambda x: x.split(',')[1]).apply(lambda x:x.split('.')[0])combine['Title'] = combine['Title'].apply(lambda x: x.strip())combine['Title'] = combine['Title'].replace(['Major','Capt','Rev','Col','Dr'],'officer')combine['Title'] = combine['Title'].replace(['Mlle','Miss'], 'Miss')combine['Title'] = combine['Title'].replace(['Mme','Ms','Mrs'], 'Mrs')combine['Title'] = combine['Title'].replace(['Master','Jonkheer'], 'Master')combine['Title'] = combine['Title'].replace(['Don', 'Sir', 'the Countess', 'Dona', 'Lady'], 'Royalty')df = pd.get_dummies(combine['Title'],prefix='Title')combine = pd.concat([combine,df], axis=1) Fare该项只有一个缺失值，对该值进行填充,我们可以按照阶级均价来填充 1combine['Fare'] = combine['Fare'].fillna(combine.groupby('Pclass')['Fare'].transform(np.mean)) 通过对Ticket简单的统计，我们可以看到部分票号数据有重复，同时结合亲属人数及名字的数据，和票价船舱等级对比，我们可以知道购买的票中有团体票，所以我们需要将团体票的票价分配到每个人的头上 123combine['Group_Ticket'] = combine['Fare'].groupby(by=combine['Ticket']).transform('count')combine['Fare'] = combine['Fare'] / combine['Group_Ticket']combine.drop(['Group_Ticket'], axis=1, inplace=True) 123456# 分级combine['Fare_1'] = np.where(combine['Fare'] &lt;= 7.91,1,0)combine['Fare_2'] = np.where((combine['Fare'] &gt; 7.91) &amp; (combine['Fare'] &lt;= 14.454),1,0)combine['Fare_3'] = np.where((combine['Fare'] &gt; 14.454)&amp; (combine['Fare'] &lt;= 31),1,0)combine['Fare_4'] = np.where((combine['Fare'] &gt; 31),1,0)combine = combine.drop('Fare',axis=1) Dead_female_family &amp; Survive_male_family前面分析可以知道，家庭的行为具有一致性，那么如果家族中有一个女的死亡，那么其他女性也倾向于死亡，反之，如果有男性生还，其他男性也会倾向于生还，为了防止模型无脑判断女性生还和男性死亡，在这里分出这两类情况。 1234567combine['Fname'] = combine['Name'].apply(lambda x:x.split(',')[0])combine['Familysize'] = combine['SibSp']+combine['Parch']dead_female_Fname = list(set(combine[(combine.Sex=='female') &amp; (combine.Age&gt;=12) &amp; (combine.Survived==0) &amp; (combine.Familysize&gt;1)]['Fname'].values))survive_male_Fname = list(set(combine[(combine.Sex=='male') &amp; (combine.Age&gt;=12) &amp; (combine.Survived==1) &amp; (combine.Familysize&gt;1)]['Fname'].values))combine['Dead_female_family'] = np.where(combine['Fname'].isin(dead_female_Fname),1,0)combine['Survive_male_family'] = np.where(combine['Fname'].isin(survive_male_Fname),1,0)combine = combine.drop(['Name','Fname','Familysize'],axis=1) AgeAge缺失值太多，可以按照阶级性别的平均年龄填充，也可以利用机器学习算法来预测,这里我们采用第一种方法 12345group = combine.groupby(['Title', 'Pclass'])['Age']combine['Age'] = group.transform(lambda x: x.fillna(x.median()))combine['IsChild'] = np.where(combine['Age']&lt;=12,1,0)# combine['Age'] = pd.cut(combine['Age'],5)combine = combine.drop(['Title'],axis=1) CabinCabin的缺失值太多，但是根据之前的分析，该特征值的有无与生还与否也相关性，所以我们将其分为两类 123combine['Cabin_0'] = np.where(combine['Cabin'].isnull(),1,0)combine['Cabin_1'] = np.where(combine['Cabin'].isnull(),0,1)combine = combine.drop('Cabin',axis=1) PclassPclass这一项，只需要将其转换为dummy形式就可以了 12df = pd.get_dummies(combine['Pclass'], prefix='Pclass')combine = pd.concat([combine, df], axis=1).drop('Pclass',axis=1) TicketTicket 在前面并没有分析，主要是因为里面有英文有数字，难以分析出规律，但是只看英文数字结合的票号，不难发现，票号前面的英文应该代表着位置信息，那么位置影响逃生路线，故将这部分提取出来做特征处理 1234567combine['Ticket_Lett'] = combine['Ticket'].apply(lambda x: str(x)[0])combine['Ticket_Lett'] = combine['Ticket_Lett'].apply(lambda x: str(x))combine['High_Survival_Ticket'] = np.where(combine['Ticket_Lett'].isin(['1', '2', 'P','9','F']),1,0)combine['mid_Survival_Ticket'] = np.where(combine['Ticket_Lett'].isin(['3','4','L','S']),1,0)combine['Low_Survival_Ticket'] = np.where(combine['Ticket_Lett'].isin(['A','W','6','7']),1,0)combine = combine.drop(['Ticket','Ticket_Lett'],axis=1) Sex对Sex进行one-hot编码 12df = pd.get_dummies(combine['Sex'], prefix='Sex')combine = pd.concat([combine, df],axis=1).drop('Sex',axis=1) Parch and SibSp亲友数量是会影响到生存率的，那么将这两项合为一项 12345combine['Family_size'] = np.where((combine['Parch']+combine['SibSp']==0),'Alone', np.where((combine['Parch']+combine['SibSp']&lt;=3),'Small','Big'))df = pd.get_dummies(combine['Family_size'], prefix='Family_size')combine = pd.concat([combine,df],axis=1).drop(['SibSp','Parch','Family_size'],axis=1) 将所有特征转换正数值型编码12345features = combine.drop(["PassengerId","Survived"], axis=1).columnsle = LabelEncoder()for feature in features: le = le.fit(combine[feature]) combine[feature] = le.transform(combine[feature]) 将训练数据和测试数据分开123x_train = combine.iloc[:891,:].drop(['PassengerId', 'Survived'],axis=1)y_train = combine.iloc[:891,:]['Survived']x_test = combine.iloc[891:,:].drop(['PassengerId','Survived'], axis=1) 模型比较123456789101112131415161718192021222324252627282930313233343536373839404142# logistic RegressionLogreg = LogisticRegression()Logreg.fit(x_train,y_train)y_pred = Logreg.predict(x_test)acc_logreg = round(Logreg.score(x_train, y_train) * 100,2)# Support Vector Machinessvc = SVC()svc.fit(x_train, y_train)y_pred = svc.predict(x_test)acc_svc = round(svc.score(x_train, y_train) *100,2)# K-Nearest Neighborsknn = KNeighborsClassifier(n_neighbors=3)knn.fit(x_train, y_train)y_pred = knn.predict(x_test)acc_knn = round(knn.score(x_train, y_train) * 100, 2)# Random Forestrf = RandomForestClassifier(n_estimators=100)rf.fit(x_train, y_train)y_pred = rf.predict(x_test)acc_rf = round(rf.score(x_train, y_train) * 100, 2)# Decision Treedec_tree = DecisionTreeClassifier()dec_tree.fit(x_train, y_train)y_pred = dec_tree.predict(x_test)acc_dec_tree = round(dec_tree.score(x_train,y_train) * 100,2)# XGBoostxgb = XGBClassifier(max_depth=3, n_estimators=300, learning_rate=0.03)xgb.fit(x_train,y_train)y_pred = xgb.predict(x_test)acc_xgb = round(xgb.score(x_train,y_train) * 100, 2)models = pd.DataFrame(&#123;'model':['Logreg','svc','knn','rf','dec_tree','xgb'], 'Score':[acc_logreg,acc_svc,acc_knn,acc_rf,acc_dec_tree,acc_xgb]&#125;)print(models.sort_values(by='Score', ascending=False)) Score model 4 99.21 dec_tree 3 99.10 rf 5 88.55 xgb 2 87.32 knn 1 87.09 svc 0 86.31 Logreg 12345# XGBxgb = XGBClassifier()xgb.fit(x_train,y_train)y_pred = xgb.predict(x_test).astype(int)# 该列必须是整型，否则格式不对，得分0分（别问我怎么知道的）# 只得到了78分的成绩 12subminssion = pd.DataFrame(&#123;"PassengerId": data_test["PassengerId"],"Survived": y_pred&#125;)subminssion.to_csv('submission.csv',index=False) 最后，提交结果后，发现得到了11% 的排名，这里没有做模型融合，模型的调参也不怎么熟练，特征工程也做的一般，所以还是有很大的优化空间的。]]></content>
      <categories>
        <category>机器学习项目</category>
        <category>kaggle</category>
      </categories>
      <tags>
        <tag>kaggle</tag>
        <tag>机器学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[统计分析之集中趋势与离中趋势]]></title>
    <url>%2Fblogs%2Fd999db0%2F</url>
    <content type="text"><![CDATA[统计指标对定量数据进行统计描述，常从集中趋势和离中趋势两个方面进行分析 集中趋势度量 指一组数据向某一中心靠拢的倾向，核心在于寻找数据的代表值或中心值 取得集中趋势代表值的方法有两种：数值平均数和 位置平均数 数值平均数 算数平均数 调和平均数 几何平均数 位置平均数 众数 中位数 数值平均数算数平均数 关注数值，鲁棒性弱（稳定性较弱，易受到异常值影响） 12345678910111213data = pd.DataFrame(&#123;'value':np.random.randint(100,120,100), 'f':np.random.rand(100)&#125;)data['f'] = data['f'] / data['f'].sum() # f为权重，这里将f列设置成总和为1的权重占比print(data.head())print('-----------------')# 算数平均值mean = data['value'].mean()print('算数平均数为：%.2f'%mean)mean_w = (data['value'] * data['f']).sum() / data['f'].sum()print('加权算数平均值为：%.2f'%mean_w)# 加权算数平均值 = (x1f1 + x2f2 + ... + xnfn) / (f1 + f2 + ... + fn) f value 0 0.014970 118 1 0.007184 116 2 0.007459 101 3 0.005892 110 4 0.016599 119 ----------------- 算数平均数为：110.09 加权算数平均值为：110.69 几何平均数 计算几何平均数要求各观察值之间存在连乘积关系，它的主要用途是 对比率、指数等进行平均 计算平均发展速度 样本数据非负，主要用于对数正态分布 复利下的平均年利率 连续作业的车间求产品的平均合格率 $$G_{n} = \sqrt[n]{x_{1}x_{2}x_{3}x_{4}x_{…}x_{n}}\$$ 几何平均数(百度百科) 123456# 一位投资者持有股票，1996年，1997年，1998年，1999年收益率分别为# 4.5%, 2.0%, 3.5%, 5.4%,# 求此4年内平均收益率from scipy.stats import gmeandata_g = gmean(data['value'])data_g 109.96165465844449 位置平均数 中位数： 关注顺序，鲁棒性强 当N为奇数时：$$m_{0.5} = X_{(N+1)/2}$$当N为偶数时：$$m_{0.5} = \frac{X_{(N/2)}+X_{(N/2+1)}}{2}$$ 众数： 关注频次 123456789101112131415161718192021222324252627282930313233# 中位数med = data['value'].median()print('中位数为%i' % med)# 中位数指将总体各单位标志按照大小顺序排列后，中间位置的数字# 众数m = data['value'].mode()print('众数为',m.tolist())# 众数是一组数据中出现次数最多的数，这里可能返回多个值# 密度曲线data['value'].plot(kind='kde',style='--k',grid=True,figsize=(10,6))# 简单算术平均plt.axvline(mean,hold=None,color='r',linestyle='--',alpha=0.8)plt.text(mean+5,0.005,'简单算术平均值：%.2f' % mean,color='r',fontsize=15)# 加权平均数plt.axvline(mean_w,hold=None,color='b',linestyle='--',alpha=0.8)plt.text(mean+5,0.01,'加权平均值：%.2f' % mean_w,color='b',fontsize=15)# 几何平均数plt.axvline(data_g,hold=None,color='g',linestyle='--',alpha=0.8)plt.text(mean+5,0.015,'几何平均值：%.2f' % data_g,color='g',fontsize=15)# 中位数plt.axvline(med,hold=None,color='y',linestyle='--',alpha=0.8)plt.text(mean+5,0.020,'几何平均值：%.2f' % med,color='y',fontsize=15) 中位数为110 众数为 [108] Text(115.09,0.02,&apos;几何平均值：110.00&apos;) 离中趋势度 是指一组数据中个数据值以不同程度偏离其中心（平均数）的趋势，又称标志变动度 12345# 创建数据，销售数据data = pd.DataFrame(&#123;'A_sale':np.random.rand(30)*1000, 'B_sale':np.random.rand(30)*1000&#125;, index = pd.period_range('20170601','20170630'))print(data.head()) A_sale B_sale 2017-06-01 574.693080 970.059264 2017-06-02 278.487440 683.602258 2017-06-03 830.472896 293.102768 2017-06-04 505.211093 268.009253 2017-06-05 316.383594 134.011541 极差与分位差 极差： 没有考虑中间值的变动情况，测定离中趋势时不准确 分位差： 从一组数据踢出部分极端值后的从新计算类似极差的指标，常用的有 四分位差，八分位差 123a_r = data['A_sale'].max() - data['A_sale'].min()b_r = data['B_sale'].max() - data['B_sale'].min()print('A产品销售额极差为：%.2f,B产品销售额极差为：%.2f'%(a_r,b_r)) A产品销售额极差为：920.98,B产品销售额极差为：914.30 123456sta = data['A_sale'].describe()stb = data['B_sale'].describe()#print(sta)a_iqr = sta.loc['75%'] - sta.loc['25%']b_iqr = stb.loc['75%'] - stb.loc['25%']print('A销售额的分位差为：%.2f, B销售额的分位差为：%.2f' % (a_iqr,b_iqr)) A销售额的分位差为：481.57, B销售额的分位差为：508.45 12345# 绘制箱型图color = dict(boxes='DarkGreen', whiskers='DarkOrange', medians='DarkBlue', caps='Gray')data.plot.box(vert=False,grid = True,color = color,figsize = (10,6))# 箱型图 方差与标准差 平均差：平均差是总体所有单位与其算术平均数的离差绝对值的算术平均数，1范数，异常值影响 $$MD = \frac{\sum_N |x - \bar{x}|}{N}$$ 方差：差的平方的均值，2范数，异常值影响 总体方差 $$\sigma^2 = \frac{\sum_N (X-E(X))^2}{N}$$ 样本方差 $$s^2 = \frac{\sum_N (x - \bar{x})^2}{N-1}$$ 标准差：方差的算数平方根（应用最广） 平均差 VS 方差：对异常值的敏感程度不同 离散系数（常用的是标准差系数：数据标准差和算数平均数的比） $$CV = \frac{\sigma}{\mu}$$ 123456789a_std = sta.loc['std']b_std = stb.loc['std']a_var = data['A_sale'].var()b_var = data['B_sale'].var()print('A销售额的标准差为：%.2f, B销售额的标准差为：%.2f' % (a_std,b_std))print('A销售额的方差为：%.2f, B销售额的方差为：%.2f' % (a_var,b_var))# 方差 → 各组中数值与算数平均数离差平方的算术平均数# 标准差 → 方差的平方根# 标准差是最常用的离中趋势指标 → 标准差越大，离中趋势越明显 A销售额的标准差为：292.12, B销售额的标准差为：293.35 A销售额的方差为：85331.19, B销售额的方差为：86052.83 1234567891011121314fig = plt.figure(figsize = (12,4))ax1 = fig.add_subplot(1,2,1)data['A_sale'].plot(kind = 'kde',style = 'k--',grid = True,title = 'A密度曲线')plt.axvline(sta.loc['50%'],hold=None,color='r',linestyle="--",alpha=0.8) plt.axvline(sta.loc['50%'] - a_std,hold=None,color='b',linestyle="--",alpha=0.8) plt.axvline(sta.loc['50%'] + a_std,hold=None,color='b',linestyle="--",alpha=0.8) # A密度曲线，1个标准差ax2 = fig.add_subplot(1,2,2)data['B_sale'].plot(kind = 'kde',style = 'k--',grid = True,title = 'B密度曲线')plt.axvline(stb.loc['50%'],hold=None,color='r',linestyle="--",alpha=0.8) plt.axvline(stb.loc['50%'] - b_std,hold=None,color='b',linestyle="--",alpha=0.8) plt.axvline(stb.loc['50%'] + b_std,hold=None,color='b',linestyle="--",alpha=0.8) # B密度曲线，1个标准差]]></content>
      <categories>
        <category>统计学习</category>
      </categories>
      <tags>
        <tag>统计学习</tag>
        <tag>特征分析</tag>
      </tags>
  </entry>
</search>
